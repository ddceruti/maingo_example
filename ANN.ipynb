{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a80e7fb5",
   "metadata": {},
   "source": [
    "# Example pymaingo ANN global solution and training\n",
    "\n",
    "From melon doc (https://git.rwth-aachen.de/avt-svt/public/MeLOn/-/blob/master/feedforward%20neural%20network/training/keras/example_training_of_ANN.py) and the ANN paper (https://link.springer.com/content/pdf/10.1007/s10957-018-1396-0.pdf).\n",
    "\n",
    "## Problem statement:\n",
    "min $f(x)$\n",
    "\n",
    "where $f$ is a feed forward neural network. \n",
    "\n",
    "The peaks function will be used as a dummy problem and will be approximated by $f$. The peaks function is defined as:\n",
    "\n",
    "$$ g_{peaks}(x_1, x_2) = 3\\cdot(1-x_1)^2 \\cdot \\exp[-x_1^2-(x_2+1)^2] -10\\cdot (x_1/5-x_1^3-x_2^5)\\cdot\\exp(-x_1^2-x_2^2)- \\exp[-(x_1+1)^2-x_2^2]/3$$\n",
    "\n",
    "$$g_{peaks} : \\mathbb{R}^2 \\to \\mathbb{R}$$\n",
    "\n",
    "The function dominion is defined as $D = \\{x_1, x_2 \\in \\mathbb{R}: -3 \\leq x_1,x_2 \\leq 3 \\}$\n",
    "\n",
    "The initial dataset will be generated by Latin hypercube sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ace0207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from pyDOE import lhs\n",
    "import maingopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90d932c",
   "metadata": {},
   "source": [
    "Implement peaks function as defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "971eea61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def peaks(X):\n",
    "    term1 = 3*np.multiply((1-X[:,0])**2, np.exp(-(X[:,0])**2-(X[:,1]+1)**2))\n",
    "    term2 = np.multiply(-10*(X[:,0]/5-X[:,0]**3-X[:,1]**5), np.exp(-X[:,0]**2-X[:,1]**2))\n",
    "    term3 = -np.exp(-(X[:,0]+1)**2-X[:,1]**2)/3\n",
    "    y = term1 + term2 + term3\n",
    "    return np.expand_dims(y, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cd87cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.55112995],\n",
       "       [ 0.37537558]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test global minimum at f(0.228, -1.626)=-6.551\n",
    "peaks(np.array([[0.228, -1.626], [0.5,0.5]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6c713a",
   "metadata": {},
   "source": [
    "## Training data generation\n",
    "\n",
    "Generate 600 samples with latin hypercube sampling (LHS) (package pyDOE), rescale to [-3, 3] and evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7439d00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lhd = lhs(2, samples=600)\n",
    "Xpeaks = lhd*6-3\n",
    "ypeaks = peaks(Xpeaks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dd4d16",
   "metadata": {},
   "source": [
    "## Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1d3211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_name = 'peaks'\n",
    "# dimensionality of the data\n",
    "input_dim = 2\n",
    "output_dim = 1\n",
    "# scale Input to [-1,1] range\n",
    "scaleInput = True\n",
    "# normalize Output to z-score\n",
    "normalizeOutput = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa483e8",
   "metadata": {},
   "source": [
    "define scale and normalize (from melon keras utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0023b053",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(X, scaleInput):\n",
    "    # scale Input values to range [-1,1] in each dimension\n",
    "    if (scaleInput):\n",
    "        nom = (X -  X.min(axis=0))*2\n",
    "        denom = X.max(axis=0) - X.min(axis=0)\n",
    "        denom[denom==0] = 1\n",
    "        return -1 + nom/denom\n",
    "    else:\n",
    "        return X\n",
    "\n",
    "def normalize(y, normalizeOutput):\n",
    "    # normalize output to z-score\n",
    "    if(normalizeOutput):\n",
    "        y_norm = (y - np.mean(y, axis=0))/np.std(y, axis=0);\n",
    "        return y_norm\n",
    "    else:\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0a9d527",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xnorm = scale(Xpeaks, scaleInput)\n",
    "ynorm = normalize(ypeaks, normalizeOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ca326bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into test, validation and test sets (70-15-15% split)\n",
    "Xtrain, Xval, ytrain, yval = train_test_split(Xnorm, ynorm, test_size=0.15)\n",
    "n_train = Xtrain.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df241dc",
   "metadata": {},
   "source": [
    "## Set output parameters\n",
    "\n",
    "Two hidden layers of 10, 8 (different from source paper)-> (2x10+1) + (10x8+1) + (8x1)+1 = 127 parameters to optimize.\n",
    "\n",
    "ReLU activation function for the all activation functions exctept the output layer, which is linear. \n",
    "\n",
    "Learning by first-order stochastic gradient descent (ADAM, https://arxiv.org/abs/1412.6980) for 100 epochs with a 0.001 leraning rate (default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa061dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output filename\n",
    "output_folder = \"./data/Output/\"\n",
    "filename_out = output_folder + problem_name\n",
    "# training parameters\n",
    "network_layout = [10, 8]\n",
    "activation_function = 'relu'\n",
    "activation_function_out = 'linear'\n",
    "learning_rate = 0.001\n",
    "kernel_regularizer = tf.keras.regularizers.l2(l=0.0001)  # L2 regularization penalty\n",
    "# 'he_normal' for relu activation, 'glorot_uniform' for everything else\n",
    "kernel_initializer = 'he_normal'\n",
    "# It draws samples from a truncated normal distribution centered on 0 with stddev = sqrt(2 / fan_in) where fan_in is the number of input units in the weight tensor.\n",
    "optimizer = 'adam'\n",
    "epochs = 1000\n",
    "#batch_size = 128\n",
    "random_state = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9289ac5b",
   "metadata": {},
   "source": [
    "## Build model\n",
    "\n",
    "With the inputs defined above:\n",
    "\n",
    "keras.sequential: a plain stack of layers where each layer has exactly one input tensor and one output tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a5c6881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (Dense)               (None, 10)                30        \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8)                 88        \n",
      "                                                                 \n",
      " output (Dense)              (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 127\n",
      "Trainable params: 127\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Sequential class: Linear stack of layers.\n",
    "model = tf.keras.Sequential()\n",
    "# Create and add first layer\n",
    "model.add(tf.keras.layers.Dense(network_layout[0],\n",
    "                                name=\"input\",\n",
    "                                kernel_initializer=kernel_initializer,\n",
    "                                kernel_regularizer=kernel_regularizer,\n",
    "                                activation=activation_function,\n",
    "                                input_dim=input_dim))\n",
    "# Create and add all remaining layers (in this case, 9x9 layout)\n",
    "for neuron in network_layout[1:]:\n",
    "    model.add(tf.keras.layers.Dense(neuron,\n",
    "                                    kernel_initializer=kernel_initializer,\n",
    "                                    kernel_regularizer=kernel_regularizer,\n",
    "                                    activation=activation_function))\n",
    "# Output layer w linear function\n",
    "model.add(tf.keras.layers.Dense(output_dim, name=\"output\",\n",
    "                                kernel_initializer='glorot_uniform',\n",
    "                                kernel_regularizer=kernel_regularizer,\n",
    "                                activation=activation_function_out))\n",
    "\n",
    "model.compile(loss='mse', optimizer=optimizer, metrics=['mse', 'mae'])\n",
    "# Generate a table summarizing the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009a904b",
   "metadata": {},
   "source": [
    "## Train ANN model on dataset\n",
    "\n",
    "First-order gradient-based optimization of stochastic objective functions (https://arxiv.org/abs/1412.6980)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50507067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "16/16 [==============================] - 1s 10ms/step - loss: 0.9538 - mse: 0.9504 - mae: 0.6804 - val_loss: 1.1203 - val_mse: 1.1168 - val_mae: 0.7712\n",
      "Epoch 2/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8645 - mse: 0.8611 - mae: 0.6364 - val_loss: 1.0464 - val_mse: 1.0430 - val_mae: 0.7323\n",
      "Epoch 3/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8210 - mse: 0.8176 - mae: 0.6216 - val_loss: 1.0123 - val_mse: 1.0089 - val_mae: 0.7237\n",
      "Epoch 4/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7975 - mse: 0.7941 - mae: 0.6176 - val_loss: 0.9907 - val_mse: 0.9873 - val_mae: 0.7187\n",
      "Epoch 5/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7801 - mse: 0.7767 - mae: 0.6134 - val_loss: 0.9719 - val_mse: 0.9686 - val_mae: 0.7110\n",
      "Epoch 6/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7651 - mse: 0.7617 - mae: 0.6062 - val_loss: 0.9610 - val_mse: 0.9576 - val_mae: 0.7048\n",
      "Epoch 7/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7532 - mse: 0.7498 - mae: 0.6026 - val_loss: 0.9498 - val_mse: 0.9465 - val_mae: 0.7036\n",
      "Epoch 8/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7435 - mse: 0.7401 - mae: 0.6023 - val_loss: 0.9393 - val_mse: 0.9359 - val_mae: 0.7017\n",
      "Epoch 9/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7334 - mse: 0.7300 - mae: 0.5933 - val_loss: 0.9322 - val_mse: 0.9288 - val_mae: 0.6900\n",
      "Epoch 10/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7237 - mse: 0.7203 - mae: 0.5871 - val_loss: 0.9220 - val_mse: 0.9187 - val_mae: 0.6868\n",
      "Epoch 11/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7138 - mse: 0.7104 - mae: 0.5828 - val_loss: 0.9135 - val_mse: 0.9101 - val_mae: 0.6829\n",
      "Epoch 12/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7028 - mse: 0.6994 - mae: 0.5762 - val_loss: 0.9034 - val_mse: 0.9000 - val_mae: 0.6779\n",
      "Epoch 13/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6925 - mse: 0.6892 - mae: 0.5685 - val_loss: 0.8955 - val_mse: 0.8921 - val_mae: 0.6728\n",
      "Epoch 14/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6840 - mse: 0.6806 - mae: 0.5655 - val_loss: 0.8834 - val_mse: 0.8800 - val_mae: 0.6695\n",
      "Epoch 15/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6748 - mse: 0.6714 - mae: 0.5634 - val_loss: 0.8757 - val_mse: 0.8723 - val_mae: 0.6654\n",
      "Epoch 16/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6679 - mse: 0.6645 - mae: 0.5574 - val_loss: 0.8690 - val_mse: 0.8656 - val_mae: 0.6612\n",
      "Epoch 17/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6576 - mse: 0.6542 - mae: 0.5554 - val_loss: 0.8570 - val_mse: 0.8536 - val_mae: 0.6588\n",
      "Epoch 18/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6487 - mse: 0.6453 - mae: 0.5519 - val_loss: 0.8517 - val_mse: 0.8483 - val_mae: 0.6557\n",
      "Epoch 19/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6413 - mse: 0.6378 - mae: 0.5472 - val_loss: 0.8446 - val_mse: 0.8412 - val_mae: 0.6498\n",
      "Epoch 20/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6329 - mse: 0.6294 - mae: 0.5429 - val_loss: 0.8325 - val_mse: 0.8290 - val_mae: 0.6461\n",
      "Epoch 21/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6267 - mse: 0.6232 - mae: 0.5403 - val_loss: 0.8270 - val_mse: 0.8236 - val_mae: 0.6441\n",
      "Epoch 22/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6180 - mse: 0.6145 - mae: 0.5369 - val_loss: 0.8201 - val_mse: 0.8166 - val_mae: 0.6394\n",
      "Epoch 23/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6128 - mse: 0.6093 - mae: 0.5324 - val_loss: 0.8184 - val_mse: 0.8149 - val_mae: 0.6349\n",
      "Epoch 24/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6053 - mse: 0.6018 - mae: 0.5277 - val_loss: 0.8063 - val_mse: 0.8028 - val_mae: 0.6314\n",
      "Epoch 25/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5991 - mse: 0.5956 - mae: 0.5286 - val_loss: 0.7992 - val_mse: 0.7957 - val_mae: 0.6338\n",
      "Epoch 26/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5940 - mse: 0.5905 - mae: 0.5295 - val_loss: 0.7920 - val_mse: 0.7885 - val_mae: 0.6317\n",
      "Epoch 27/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5910 - mse: 0.5874 - mae: 0.5280 - val_loss: 0.7923 - val_mse: 0.7888 - val_mae: 0.6302\n",
      "Epoch 28/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5848 - mse: 0.5812 - mae: 0.5205 - val_loss: 0.7822 - val_mse: 0.7787 - val_mae: 0.6244\n",
      "Epoch 29/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5777 - mse: 0.5742 - mae: 0.5202 - val_loss: 0.7759 - val_mse: 0.7723 - val_mae: 0.6266\n",
      "Epoch 30/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5729 - mse: 0.5693 - mae: 0.5182 - val_loss: 0.7716 - val_mse: 0.7680 - val_mae: 0.6251\n",
      "Epoch 31/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5678 - mse: 0.5642 - mae: 0.5165 - val_loss: 0.7688 - val_mse: 0.7652 - val_mae: 0.6218\n",
      "Epoch 32/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5652 - mse: 0.5616 - mae: 0.5145 - val_loss: 0.7593 - val_mse: 0.7557 - val_mae: 0.6205\n",
      "Epoch 33/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5588 - mse: 0.5552 - mae: 0.5132 - val_loss: 0.7575 - val_mse: 0.7539 - val_mae: 0.6183\n",
      "Epoch 34/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5555 - mse: 0.5519 - mae: 0.5101 - val_loss: 0.7516 - val_mse: 0.7480 - val_mae: 0.6159\n",
      "Epoch 35/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5523 - mse: 0.5487 - mae: 0.5113 - val_loss: 0.7468 - val_mse: 0.7431 - val_mae: 0.6154\n",
      "Epoch 36/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5492 - mse: 0.5456 - mae: 0.5059 - val_loss: 0.7425 - val_mse: 0.7389 - val_mae: 0.6118\n",
      "Epoch 37/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5466 - mse: 0.5429 - mae: 0.5071 - val_loss: 0.7386 - val_mse: 0.7349 - val_mae: 0.6104\n",
      "Epoch 38/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5418 - mse: 0.5381 - mae: 0.5079 - val_loss: 0.7286 - val_mse: 0.7250 - val_mae: 0.6118\n",
      "Epoch 39/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5369 - mse: 0.5332 - mae: 0.5038 - val_loss: 0.7308 - val_mse: 0.7271 - val_mae: 0.6071\n",
      "Epoch 40/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5319 - mse: 0.5282 - mae: 0.5000 - val_loss: 0.7224 - val_mse: 0.7187 - val_mae: 0.6047\n",
      "Epoch 41/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5294 - mse: 0.5257 - mae: 0.4978 - val_loss: 0.7150 - val_mse: 0.7113 - val_mae: 0.6013\n",
      "Epoch 42/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5252 - mse: 0.5214 - mae: 0.4951 - val_loss: 0.7133 - val_mse: 0.7096 - val_mae: 0.5975\n",
      "Epoch 43/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5215 - mse: 0.5177 - mae: 0.4952 - val_loss: 0.7080 - val_mse: 0.7042 - val_mae: 0.5993\n",
      "Epoch 44/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5179 - mse: 0.5142 - mae: 0.4960 - val_loss: 0.7024 - val_mse: 0.6987 - val_mae: 0.5948\n",
      "Epoch 45/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5143 - mse: 0.5106 - mae: 0.4928 - val_loss: 0.6999 - val_mse: 0.6961 - val_mae: 0.5938\n",
      "Epoch 46/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5121 - mse: 0.5083 - mae: 0.4902 - val_loss: 0.6954 - val_mse: 0.6917 - val_mae: 0.5909\n",
      "Epoch 47/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5076 - mse: 0.5038 - mae: 0.4896 - val_loss: 0.6922 - val_mse: 0.6885 - val_mae: 0.5905\n",
      "Epoch 48/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5050 - mse: 0.5012 - mae: 0.4905 - val_loss: 0.6900 - val_mse: 0.6862 - val_mae: 0.5915\n",
      "Epoch 49/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5014 - mse: 0.4976 - mae: 0.4881 - val_loss: 0.6854 - val_mse: 0.6815 - val_mae: 0.5884\n",
      "Epoch 50/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4982 - mse: 0.4944 - mae: 0.4852 - val_loss: 0.6826 - val_mse: 0.6788 - val_mae: 0.5864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4952 - mse: 0.4914 - mae: 0.4837 - val_loss: 0.6779 - val_mse: 0.6740 - val_mae: 0.5843\n",
      "Epoch 52/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4924 - mse: 0.4886 - mae: 0.4836 - val_loss: 0.6769 - val_mse: 0.6731 - val_mae: 0.5837\n",
      "Epoch 53/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4902 - mse: 0.4863 - mae: 0.4837 - val_loss: 0.6723 - val_mse: 0.6684 - val_mae: 0.5827\n",
      "Epoch 54/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4933 - mse: 0.4894 - mae: 0.4857 - val_loss: 0.6725 - val_mse: 0.6686 - val_mae: 0.5808\n",
      "Epoch 55/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4851 - mse: 0.4812 - mae: 0.4805 - val_loss: 0.6620 - val_mse: 0.6580 - val_mae: 0.5764\n",
      "Epoch 56/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4828 - mse: 0.4789 - mae: 0.4783 - val_loss: 0.6667 - val_mse: 0.6627 - val_mae: 0.5786\n",
      "Epoch 57/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4789 - mse: 0.4750 - mae: 0.4775 - val_loss: 0.6565 - val_mse: 0.6525 - val_mae: 0.5715\n",
      "Epoch 58/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4763 - mse: 0.4723 - mae: 0.4763 - val_loss: 0.6568 - val_mse: 0.6528 - val_mae: 0.5749\n",
      "Epoch 59/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4754 - mse: 0.4715 - mae: 0.4757 - val_loss: 0.6542 - val_mse: 0.6502 - val_mae: 0.5670\n",
      "Epoch 60/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4712 - mse: 0.4672 - mae: 0.4737 - val_loss: 0.6440 - val_mse: 0.6400 - val_mae: 0.5690\n",
      "Epoch 61/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4682 - mse: 0.4642 - mae: 0.4719 - val_loss: 0.6447 - val_mse: 0.6407 - val_mae: 0.5660\n",
      "Epoch 62/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4651 - mse: 0.4611 - mae: 0.4715 - val_loss: 0.6449 - val_mse: 0.6409 - val_mae: 0.5666\n",
      "Epoch 63/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4630 - mse: 0.4590 - mae: 0.4681 - val_loss: 0.6393 - val_mse: 0.6353 - val_mae: 0.5616\n",
      "Epoch 64/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4611 - mse: 0.4570 - mae: 0.4683 - val_loss: 0.6356 - val_mse: 0.6315 - val_mae: 0.5630\n",
      "Epoch 65/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4578 - mse: 0.4537 - mae: 0.4682 - val_loss: 0.6309 - val_mse: 0.6268 - val_mae: 0.5619\n",
      "Epoch 66/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4556 - mse: 0.4515 - mae: 0.4675 - val_loss: 0.6306 - val_mse: 0.6265 - val_mae: 0.5594\n",
      "Epoch 67/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4528 - mse: 0.4487 - mae: 0.4651 - val_loss: 0.6252 - val_mse: 0.6211 - val_mae: 0.5550\n",
      "Epoch 68/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4510 - mse: 0.4468 - mae: 0.4629 - val_loss: 0.6209 - val_mse: 0.6168 - val_mae: 0.5539\n",
      "Epoch 69/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4480 - mse: 0.4439 - mae: 0.4614 - val_loss: 0.6229 - val_mse: 0.6188 - val_mae: 0.5528\n",
      "Epoch 70/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4484 - mse: 0.4442 - mae: 0.4639 - val_loss: 0.6187 - val_mse: 0.6145 - val_mae: 0.5529\n",
      "Epoch 71/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4440 - mse: 0.4398 - mae: 0.4610 - val_loss: 0.6126 - val_mse: 0.6084 - val_mae: 0.5513\n",
      "Epoch 72/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4406 - mse: 0.4364 - mae: 0.4590 - val_loss: 0.6149 - val_mse: 0.6107 - val_mae: 0.5501\n",
      "Epoch 73/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4407 - mse: 0.4365 - mae: 0.4611 - val_loss: 0.6052 - val_mse: 0.6009 - val_mae: 0.5482\n",
      "Epoch 74/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4368 - mse: 0.4326 - mae: 0.4573 - val_loss: 0.6092 - val_mse: 0.6050 - val_mae: 0.5472\n",
      "Epoch 75/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4350 - mse: 0.4308 - mae: 0.4566 - val_loss: 0.6048 - val_mse: 0.6005 - val_mae: 0.5447\n",
      "Epoch 76/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4337 - mse: 0.4294 - mae: 0.4569 - val_loss: 0.6000 - val_mse: 0.5958 - val_mae: 0.5438\n",
      "Epoch 77/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4306 - mse: 0.4263 - mae: 0.4551 - val_loss: 0.5963 - val_mse: 0.5920 - val_mae: 0.5424\n",
      "Epoch 78/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4294 - mse: 0.4250 - mae: 0.4549 - val_loss: 0.5925 - val_mse: 0.5882 - val_mae: 0.5421\n",
      "Epoch 79/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4267 - mse: 0.4224 - mae: 0.4546 - val_loss: 0.5940 - val_mse: 0.5896 - val_mae: 0.5413\n",
      "Epoch 80/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4250 - mse: 0.4207 - mae: 0.4536 - val_loss: 0.5884 - val_mse: 0.5840 - val_mae: 0.5388\n",
      "Epoch 81/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4236 - mse: 0.4192 - mae: 0.4543 - val_loss: 0.5867 - val_mse: 0.5824 - val_mae: 0.5385\n",
      "Epoch 82/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4204 - mse: 0.4160 - mae: 0.4502 - val_loss: 0.5865 - val_mse: 0.5821 - val_mae: 0.5362\n",
      "Epoch 83/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4201 - mse: 0.4157 - mae: 0.4501 - val_loss: 0.5797 - val_mse: 0.5753 - val_mae: 0.5341\n",
      "Epoch 84/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4216 - mse: 0.4172 - mae: 0.4549 - val_loss: 0.5800 - val_mse: 0.5756 - val_mae: 0.5365\n",
      "Epoch 85/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4153 - mse: 0.4109 - mae: 0.4479 - val_loss: 0.5786 - val_mse: 0.5741 - val_mae: 0.5326\n",
      "Epoch 86/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4134 - mse: 0.4089 - mae: 0.4465 - val_loss: 0.5775 - val_mse: 0.5731 - val_mae: 0.5332\n",
      "Epoch 87/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4115 - mse: 0.4070 - mae: 0.4472 - val_loss: 0.5742 - val_mse: 0.5697 - val_mae: 0.5328\n",
      "Epoch 88/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4110 - mse: 0.4065 - mae: 0.4472 - val_loss: 0.5695 - val_mse: 0.5650 - val_mae: 0.5289\n",
      "Epoch 89/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4087 - mse: 0.4042 - mae: 0.4445 - val_loss: 0.5682 - val_mse: 0.5637 - val_mae: 0.5274\n",
      "Epoch 90/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4082 - mse: 0.4037 - mae: 0.4458 - val_loss: 0.5684 - val_mse: 0.5638 - val_mae: 0.5280\n",
      "Epoch 91/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4047 - mse: 0.4001 - mae: 0.4433 - val_loss: 0.5634 - val_mse: 0.5589 - val_mae: 0.5270\n",
      "Epoch 92/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4027 - mse: 0.3982 - mae: 0.4434 - val_loss: 0.5618 - val_mse: 0.5573 - val_mae: 0.5272\n",
      "Epoch 93/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4019 - mse: 0.3973 - mae: 0.4433 - val_loss: 0.5589 - val_mse: 0.5543 - val_mae: 0.5251\n",
      "Epoch 94/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3996 - mse: 0.3950 - mae: 0.4411 - val_loss: 0.5574 - val_mse: 0.5528 - val_mae: 0.5243\n",
      "Epoch 95/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4001 - mse: 0.3955 - mae: 0.4402 - val_loss: 0.5574 - val_mse: 0.5528 - val_mae: 0.5231\n",
      "Epoch 96/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4000 - mse: 0.3954 - mae: 0.4425 - val_loss: 0.5566 - val_mse: 0.5520 - val_mae: 0.5235\n",
      "Epoch 97/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3944 - mse: 0.3897 - mae: 0.4375 - val_loss: 0.5514 - val_mse: 0.5467 - val_mae: 0.5184\n",
      "Epoch 98/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3939 - mse: 0.3892 - mae: 0.4384 - val_loss: 0.5491 - val_mse: 0.5444 - val_mae: 0.5206\n",
      "Epoch 99/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3920 - mse: 0.3873 - mae: 0.4382 - val_loss: 0.5463 - val_mse: 0.5416 - val_mae: 0.5167\n",
      "Epoch 100/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3904 - mse: 0.3856 - mae: 0.4368 - val_loss: 0.5416 - val_mse: 0.5369 - val_mae: 0.5151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3900 - mse: 0.3852 - mae: 0.4379 - val_loss: 0.5455 - val_mse: 0.5408 - val_mae: 0.5170\n",
      "Epoch 102/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3881 - mse: 0.3834 - mae: 0.4359 - val_loss: 0.5430 - val_mse: 0.5383 - val_mae: 0.5147\n",
      "Epoch 103/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3901 - mse: 0.3854 - mae: 0.4385 - val_loss: 0.5389 - val_mse: 0.5341 - val_mae: 0.5128\n",
      "Epoch 104/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3884 - mse: 0.3836 - mae: 0.4339 - val_loss: 0.5367 - val_mse: 0.5319 - val_mae: 0.5126\n",
      "Epoch 105/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3843 - mse: 0.3795 - mae: 0.4360 - val_loss: 0.5399 - val_mse: 0.5351 - val_mae: 0.5152\n",
      "Epoch 106/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3824 - mse: 0.3776 - mae: 0.4328 - val_loss: 0.5338 - val_mse: 0.5290 - val_mae: 0.5118\n",
      "Epoch 107/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3808 - mse: 0.3760 - mae: 0.4322 - val_loss: 0.5351 - val_mse: 0.5303 - val_mae: 0.5126\n",
      "Epoch 108/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3786 - mse: 0.3738 - mae: 0.4325 - val_loss: 0.5304 - val_mse: 0.5255 - val_mae: 0.5087\n",
      "Epoch 109/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3799 - mse: 0.3751 - mae: 0.4304 - val_loss: 0.5315 - val_mse: 0.5266 - val_mae: 0.5101\n",
      "Epoch 110/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3759 - mse: 0.3710 - mae: 0.4306 - val_loss: 0.5284 - val_mse: 0.5236 - val_mae: 0.5073\n",
      "Epoch 111/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3745 - mse: 0.3696 - mae: 0.4299 - val_loss: 0.5236 - val_mse: 0.5187 - val_mae: 0.5064\n",
      "Epoch 112/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3740 - mse: 0.3691 - mae: 0.4279 - val_loss: 0.5225 - val_mse: 0.5175 - val_mae: 0.5042\n",
      "Epoch 113/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3733 - mse: 0.3684 - mae: 0.4304 - val_loss: 0.5249 - val_mse: 0.5200 - val_mae: 0.5079\n",
      "Epoch 114/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3714 - mse: 0.3665 - mae: 0.4271 - val_loss: 0.5200 - val_mse: 0.5151 - val_mae: 0.5006\n",
      "Epoch 115/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3716 - mse: 0.3667 - mae: 0.4253 - val_loss: 0.5219 - val_mse: 0.5170 - val_mae: 0.5060\n",
      "Epoch 116/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3713 - mse: 0.3664 - mae: 0.4297 - val_loss: 0.5184 - val_mse: 0.5135 - val_mae: 0.5022\n",
      "Epoch 117/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3668 - mse: 0.3618 - mae: 0.4250 - val_loss: 0.5156 - val_mse: 0.5106 - val_mae: 0.5015\n",
      "Epoch 118/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3676 - mse: 0.3626 - mae: 0.4260 - val_loss: 0.5131 - val_mse: 0.5081 - val_mae: 0.4999\n",
      "Epoch 119/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3668 - mse: 0.3618 - mae: 0.4263 - val_loss: 0.5159 - val_mse: 0.5109 - val_mae: 0.5012\n",
      "Epoch 120/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3657 - mse: 0.3607 - mae: 0.4230 - val_loss: 0.5097 - val_mse: 0.5047 - val_mae: 0.4977\n",
      "Epoch 121/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3651 - mse: 0.3600 - mae: 0.4267 - val_loss: 0.5140 - val_mse: 0.5090 - val_mae: 0.5008\n",
      "Epoch 122/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3617 - mse: 0.3567 - mae: 0.4220 - val_loss: 0.5064 - val_mse: 0.5013 - val_mae: 0.4941\n",
      "Epoch 123/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3612 - mse: 0.3562 - mae: 0.4209 - val_loss: 0.5093 - val_mse: 0.5042 - val_mae: 0.4973\n",
      "Epoch 124/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3595 - mse: 0.3544 - mae: 0.4219 - val_loss: 0.5068 - val_mse: 0.5017 - val_mae: 0.4986\n",
      "Epoch 125/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3595 - mse: 0.3544 - mae: 0.4211 - val_loss: 0.5069 - val_mse: 0.5018 - val_mae: 0.4975\n",
      "Epoch 126/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3584 - mse: 0.3533 - mae: 0.4236 - val_loss: 0.5062 - val_mse: 0.5011 - val_mae: 0.4959\n",
      "Epoch 127/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3581 - mse: 0.3529 - mae: 0.4179 - val_loss: 0.5015 - val_mse: 0.4964 - val_mae: 0.4913\n",
      "Epoch 128/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3553 - mse: 0.3502 - mae: 0.4195 - val_loss: 0.5013 - val_mse: 0.4961 - val_mae: 0.4930\n",
      "Epoch 129/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3567 - mse: 0.3515 - mae: 0.4220 - val_loss: 0.4993 - val_mse: 0.4941 - val_mae: 0.4925\n",
      "Epoch 130/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3531 - mse: 0.3479 - mae: 0.4191 - val_loss: 0.5007 - val_mse: 0.4955 - val_mae: 0.4920\n",
      "Epoch 131/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3522 - mse: 0.3470 - mae: 0.4178 - val_loss: 0.4952 - val_mse: 0.4900 - val_mae: 0.4892\n",
      "Epoch 132/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3527 - mse: 0.3475 - mae: 0.4140 - val_loss: 0.4974 - val_mse: 0.4922 - val_mae: 0.4905\n",
      "Epoch 133/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3511 - mse: 0.3459 - mae: 0.4169 - val_loss: 0.4989 - val_mse: 0.4937 - val_mae: 0.4923\n",
      "Epoch 134/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3507 - mse: 0.3454 - mae: 0.4196 - val_loss: 0.4905 - val_mse: 0.4853 - val_mae: 0.4851\n",
      "Epoch 135/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3492 - mse: 0.3440 - mae: 0.4135 - val_loss: 0.4919 - val_mse: 0.4867 - val_mae: 0.4868\n",
      "Epoch 136/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3483 - mse: 0.3431 - mae: 0.4172 - val_loss: 0.4905 - val_mse: 0.4853 - val_mae: 0.4872\n",
      "Epoch 137/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3467 - mse: 0.3414 - mae: 0.4142 - val_loss: 0.4829 - val_mse: 0.4776 - val_mae: 0.4814\n",
      "Epoch 138/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3466 - mse: 0.3413 - mae: 0.4125 - val_loss: 0.4911 - val_mse: 0.4858 - val_mae: 0.4863\n",
      "Epoch 139/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3447 - mse: 0.3394 - mae: 0.4160 - val_loss: 0.4880 - val_mse: 0.4827 - val_mae: 0.4847\n",
      "Epoch 140/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3440 - mse: 0.3387 - mae: 0.4114 - val_loss: 0.4840 - val_mse: 0.4787 - val_mae: 0.4834\n",
      "Epoch 141/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3426 - mse: 0.3373 - mae: 0.4144 - val_loss: 0.4827 - val_mse: 0.4774 - val_mae: 0.4802\n",
      "Epoch 142/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3432 - mse: 0.3378 - mae: 0.4103 - val_loss: 0.4843 - val_mse: 0.4790 - val_mae: 0.4815\n",
      "Epoch 143/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3419 - mse: 0.3365 - mae: 0.4124 - val_loss: 0.4778 - val_mse: 0.4724 - val_mae: 0.4792\n",
      "Epoch 144/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3404 - mse: 0.3351 - mae: 0.4121 - val_loss: 0.4760 - val_mse: 0.4706 - val_mae: 0.4741\n",
      "Epoch 145/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3386 - mse: 0.3332 - mae: 0.4074 - val_loss: 0.4777 - val_mse: 0.4723 - val_mae: 0.4779\n",
      "Epoch 146/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3375 - mse: 0.3321 - mae: 0.4082 - val_loss: 0.4765 - val_mse: 0.4711 - val_mae: 0.4762\n",
      "Epoch 147/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3377 - mse: 0.3323 - mae: 0.4126 - val_loss: 0.4764 - val_mse: 0.4710 - val_mae: 0.4749\n",
      "Epoch 148/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3368 - mse: 0.3313 - mae: 0.4044 - val_loss: 0.4755 - val_mse: 0.4700 - val_mae: 0.4734\n",
      "Epoch 149/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3356 - mse: 0.3302 - mae: 0.4074 - val_loss: 0.4694 - val_mse: 0.4640 - val_mae: 0.4708\n",
      "Epoch 150/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3370 - mse: 0.3316 - mae: 0.4122 - val_loss: 0.4681 - val_mse: 0.4626 - val_mae: 0.4699\n",
      "Epoch 151/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3332 - mse: 0.3277 - mae: 0.4028 - val_loss: 0.4699 - val_mse: 0.4644 - val_mae: 0.4717\n",
      "Epoch 152/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3339 - mse: 0.3285 - mae: 0.4083 - val_loss: 0.4720 - val_mse: 0.4665 - val_mae: 0.4747\n",
      "Epoch 153/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3313 - mse: 0.3259 - mae: 0.4026 - val_loss: 0.4680 - val_mse: 0.4626 - val_mae: 0.4724\n",
      "Epoch 154/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3309 - mse: 0.3254 - mae: 0.4081 - val_loss: 0.4643 - val_mse: 0.4588 - val_mae: 0.4677\n",
      "Epoch 155/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3286 - mse: 0.3231 - mae: 0.4004 - val_loss: 0.4653 - val_mse: 0.4597 - val_mae: 0.4672\n",
      "Epoch 156/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3266 - mse: 0.3211 - mae: 0.4022 - val_loss: 0.4683 - val_mse: 0.4628 - val_mae: 0.4728\n",
      "Epoch 157/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3265 - mse: 0.3210 - mae: 0.4023 - val_loss: 0.4643 - val_mse: 0.4587 - val_mae: 0.4698\n",
      "Epoch 158/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3256 - mse: 0.3200 - mae: 0.4004 - val_loss: 0.4615 - val_mse: 0.4559 - val_mae: 0.4656\n",
      "Epoch 159/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3252 - mse: 0.3196 - mae: 0.4018 - val_loss: 0.4619 - val_mse: 0.4564 - val_mae: 0.4705\n",
      "Epoch 160/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3237 - mse: 0.3181 - mae: 0.4000 - val_loss: 0.4601 - val_mse: 0.4545 - val_mae: 0.4654\n",
      "Epoch 161/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3233 - mse: 0.3177 - mae: 0.3986 - val_loss: 0.4584 - val_mse: 0.4528 - val_mae: 0.4671\n",
      "Epoch 162/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3220 - mse: 0.3164 - mae: 0.4021 - val_loss: 0.4594 - val_mse: 0.4538 - val_mae: 0.4683\n",
      "Epoch 163/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3208 - mse: 0.3151 - mae: 0.3975 - val_loss: 0.4565 - val_mse: 0.4508 - val_mae: 0.4627\n",
      "Epoch 164/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3198 - mse: 0.3142 - mae: 0.3973 - val_loss: 0.4559 - val_mse: 0.4503 - val_mae: 0.4646\n",
      "Epoch 165/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3205 - mse: 0.3149 - mae: 0.4006 - val_loss: 0.4509 - val_mse: 0.4453 - val_mae: 0.4580\n",
      "Epoch 166/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3189 - mse: 0.3132 - mae: 0.3957 - val_loss: 0.4565 - val_mse: 0.4509 - val_mae: 0.4689\n",
      "Epoch 167/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3182 - mse: 0.3125 - mae: 0.3966 - val_loss: 0.4564 - val_mse: 0.4507 - val_mae: 0.4681\n",
      "Epoch 168/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3160 - mse: 0.3103 - mae: 0.3982 - val_loss: 0.4489 - val_mse: 0.4432 - val_mae: 0.4611\n",
      "Epoch 169/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3148 - mse: 0.3091 - mae: 0.3941 - val_loss: 0.4485 - val_mse: 0.4428 - val_mae: 0.4604\n",
      "Epoch 170/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3140 - mse: 0.3083 - mae: 0.3954 - val_loss: 0.4466 - val_mse: 0.4409 - val_mae: 0.4588\n",
      "Epoch 171/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3151 - mse: 0.3094 - mae: 0.3916 - val_loss: 0.4502 - val_mse: 0.4445 - val_mae: 0.4624\n",
      "Epoch 172/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3138 - mse: 0.3080 - mae: 0.3981 - val_loss: 0.4406 - val_mse: 0.4349 - val_mae: 0.4529\n",
      "Epoch 173/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3098 - mse: 0.3041 - mae: 0.3894 - val_loss: 0.4389 - val_mse: 0.4332 - val_mae: 0.4552\n",
      "Epoch 174/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3095 - mse: 0.3038 - mae: 0.3913 - val_loss: 0.4435 - val_mse: 0.4377 - val_mae: 0.4606\n",
      "Epoch 175/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3093 - mse: 0.3035 - mae: 0.3927 - val_loss: 0.4391 - val_mse: 0.4334 - val_mae: 0.4542\n",
      "Epoch 176/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3068 - mse: 0.3010 - mae: 0.3884 - val_loss: 0.4400 - val_mse: 0.4342 - val_mae: 0.4569\n",
      "Epoch 177/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3055 - mse: 0.2997 - mae: 0.3928 - val_loss: 0.4347 - val_mse: 0.4289 - val_mae: 0.4525\n",
      "Epoch 178/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3040 - mse: 0.2982 - mae: 0.3887 - val_loss: 0.4347 - val_mse: 0.4289 - val_mae: 0.4530\n",
      "Epoch 179/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3030 - mse: 0.2972 - mae: 0.3873 - val_loss: 0.4297 - val_mse: 0.4239 - val_mae: 0.4468\n",
      "Epoch 180/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3029 - mse: 0.2971 - mae: 0.3888 - val_loss: 0.4311 - val_mse: 0.4252 - val_mae: 0.4533\n",
      "Epoch 181/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3022 - mse: 0.2964 - mae: 0.3883 - val_loss: 0.4275 - val_mse: 0.4217 - val_mae: 0.4478\n",
      "Epoch 182/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3086 - mse: 0.3028 - mae: 0.3964 - val_loss: 0.4212 - val_mse: 0.4153 - val_mae: 0.4400\n",
      "Epoch 183/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2997 - mse: 0.2938 - mae: 0.3829 - val_loss: 0.4244 - val_mse: 0.4185 - val_mae: 0.4514\n",
      "Epoch 184/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2985 - mse: 0.2926 - mae: 0.3897 - val_loss: 0.4261 - val_mse: 0.4202 - val_mae: 0.4466\n",
      "Epoch 185/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2967 - mse: 0.2908 - mae: 0.3860 - val_loss: 0.4227 - val_mse: 0.4168 - val_mae: 0.4461\n",
      "Epoch 186/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2957 - mse: 0.2898 - mae: 0.3834 - val_loss: 0.4171 - val_mse: 0.4112 - val_mae: 0.4415\n",
      "Epoch 187/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2940 - mse: 0.2881 - mae: 0.3843 - val_loss: 0.4202 - val_mse: 0.4143 - val_mae: 0.4457\n",
      "Epoch 188/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2942 - mse: 0.2883 - mae: 0.3839 - val_loss: 0.4191 - val_mse: 0.4132 - val_mae: 0.4425\n",
      "Epoch 189/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2924 - mse: 0.2864 - mae: 0.3810 - val_loss: 0.4170 - val_mse: 0.4111 - val_mae: 0.4434\n",
      "Epoch 190/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2911 - mse: 0.2852 - mae: 0.3825 - val_loss: 0.4173 - val_mse: 0.4113 - val_mae: 0.4447\n",
      "Epoch 191/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2901 - mse: 0.2841 - mae: 0.3784 - val_loss: 0.4118 - val_mse: 0.4059 - val_mae: 0.4391\n",
      "Epoch 192/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2903 - mse: 0.2843 - mae: 0.3823 - val_loss: 0.4169 - val_mse: 0.4109 - val_mae: 0.4464\n",
      "Epoch 193/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2885 - mse: 0.2825 - mae: 0.3798 - val_loss: 0.4113 - val_mse: 0.4053 - val_mae: 0.4397\n",
      "Epoch 194/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2879 - mse: 0.2819 - mae: 0.3797 - val_loss: 0.4136 - val_mse: 0.4076 - val_mae: 0.4451\n",
      "Epoch 195/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2877 - mse: 0.2817 - mae: 0.3796 - val_loss: 0.4055 - val_mse: 0.3994 - val_mae: 0.4362\n",
      "Epoch 196/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2875 - mse: 0.2815 - mae: 0.3793 - val_loss: 0.4085 - val_mse: 0.4025 - val_mae: 0.4406\n",
      "Epoch 197/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2855 - mse: 0.2795 - mae: 0.3814 - val_loss: 0.4141 - val_mse: 0.4081 - val_mae: 0.4445\n",
      "Epoch 198/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2860 - mse: 0.2799 - mae: 0.3770 - val_loss: 0.4068 - val_mse: 0.4007 - val_mae: 0.4380\n",
      "Epoch 199/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2828 - mse: 0.2767 - mae: 0.3771 - val_loss: 0.4023 - val_mse: 0.3962 - val_mae: 0.4348\n",
      "Epoch 200/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2824 - mse: 0.2763 - mae: 0.3757 - val_loss: 0.4017 - val_mse: 0.3956 - val_mae: 0.4346\n",
      "Epoch 201/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2826 - mse: 0.2765 - mae: 0.3774 - val_loss: 0.3989 - val_mse: 0.3928 - val_mae: 0.4305\n",
      "Epoch 202/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2822 - mse: 0.2761 - mae: 0.3751 - val_loss: 0.4049 - val_mse: 0.3988 - val_mae: 0.4410\n",
      "Epoch 203/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2793 - mse: 0.2731 - mae: 0.3753 - val_loss: 0.3979 - val_mse: 0.3918 - val_mae: 0.4265\n",
      "Epoch 204/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2785 - mse: 0.2723 - mae: 0.3701 - val_loss: 0.3983 - val_mse: 0.3922 - val_mae: 0.4337\n",
      "Epoch 205/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2768 - mse: 0.2706 - mae: 0.3731 - val_loss: 0.3970 - val_mse: 0.3908 - val_mae: 0.4296\n",
      "Epoch 206/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2757 - mse: 0.2695 - mae: 0.3695 - val_loss: 0.3972 - val_mse: 0.3911 - val_mae: 0.4301\n",
      "Epoch 207/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2755 - mse: 0.2694 - mae: 0.3737 - val_loss: 0.3932 - val_mse: 0.3870 - val_mae: 0.4243\n",
      "Epoch 208/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2752 - mse: 0.2690 - mae: 0.3684 - val_loss: 0.3949 - val_mse: 0.3887 - val_mae: 0.4308\n",
      "Epoch 209/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2741 - mse: 0.2679 - mae: 0.3719 - val_loss: 0.3891 - val_mse: 0.3828 - val_mae: 0.4208\n",
      "Epoch 210/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2723 - mse: 0.2661 - mae: 0.3656 - val_loss: 0.3872 - val_mse: 0.3809 - val_mae: 0.4216\n",
      "Epoch 211/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2714 - mse: 0.2652 - mae: 0.3682 - val_loss: 0.3875 - val_mse: 0.3813 - val_mae: 0.4211\n",
      "Epoch 212/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2701 - mse: 0.2639 - mae: 0.3644 - val_loss: 0.3869 - val_mse: 0.3806 - val_mae: 0.4250\n",
      "Epoch 213/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2686 - mse: 0.2623 - mae: 0.3671 - val_loss: 0.3878 - val_mse: 0.3815 - val_mae: 0.4217\n",
      "Epoch 214/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2676 - mse: 0.2613 - mae: 0.3652 - val_loss: 0.3866 - val_mse: 0.3803 - val_mae: 0.4209\n",
      "Epoch 215/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2670 - mse: 0.2607 - mae: 0.3625 - val_loss: 0.3822 - val_mse: 0.3759 - val_mae: 0.4198\n",
      "Epoch 216/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2672 - mse: 0.2609 - mae: 0.3651 - val_loss: 0.3826 - val_mse: 0.3762 - val_mae: 0.4226\n",
      "Epoch 217/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2656 - mse: 0.2593 - mae: 0.3612 - val_loss: 0.3781 - val_mse: 0.3718 - val_mae: 0.4141\n",
      "Epoch 218/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2629 - mse: 0.2565 - mae: 0.3601 - val_loss: 0.3832 - val_mse: 0.3769 - val_mae: 0.4196\n",
      "Epoch 219/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2638 - mse: 0.2575 - mae: 0.3613 - val_loss: 0.3745 - val_mse: 0.3682 - val_mae: 0.4090\n",
      "Epoch 220/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2620 - mse: 0.2556 - mae: 0.3584 - val_loss: 0.3829 - val_mse: 0.3765 - val_mae: 0.4244\n",
      "Epoch 221/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2604 - mse: 0.2540 - mae: 0.3589 - val_loss: 0.3745 - val_mse: 0.3681 - val_mae: 0.4102\n",
      "Epoch 222/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2593 - mse: 0.2529 - mae: 0.3554 - val_loss: 0.3755 - val_mse: 0.3691 - val_mae: 0.4136\n",
      "Epoch 223/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2588 - mse: 0.2524 - mae: 0.3569 - val_loss: 0.3702 - val_mse: 0.3638 - val_mae: 0.4073\n",
      "Epoch 224/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2576 - mse: 0.2512 - mae: 0.3539 - val_loss: 0.3712 - val_mse: 0.3648 - val_mae: 0.4081\n",
      "Epoch 225/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2561 - mse: 0.2497 - mae: 0.3508 - val_loss: 0.3709 - val_mse: 0.3644 - val_mae: 0.4106\n",
      "Epoch 226/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2555 - mse: 0.2491 - mae: 0.3540 - val_loss: 0.3682 - val_mse: 0.3618 - val_mae: 0.4059\n",
      "Epoch 227/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2550 - mse: 0.2485 - mae: 0.3526 - val_loss: 0.3665 - val_mse: 0.3601 - val_mae: 0.4052\n",
      "Epoch 228/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2556 - mse: 0.2491 - mae: 0.3518 - val_loss: 0.3682 - val_mse: 0.3618 - val_mae: 0.4091\n",
      "Epoch 229/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2525 - mse: 0.2460 - mae: 0.3484 - val_loss: 0.3654 - val_mse: 0.3589 - val_mae: 0.4027\n",
      "Epoch 230/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2530 - mse: 0.2465 - mae: 0.3506 - val_loss: 0.3619 - val_mse: 0.3554 - val_mae: 0.4020\n",
      "Epoch 231/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2504 - mse: 0.2438 - mae: 0.3476 - val_loss: 0.3658 - val_mse: 0.3593 - val_mae: 0.4062\n",
      "Epoch 232/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2494 - mse: 0.2429 - mae: 0.3460 - val_loss: 0.3627 - val_mse: 0.3561 - val_mae: 0.4012\n",
      "Epoch 233/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2484 - mse: 0.2418 - mae: 0.3463 - val_loss: 0.3620 - val_mse: 0.3554 - val_mae: 0.4030\n",
      "Epoch 234/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2481 - mse: 0.2415 - mae: 0.3451 - val_loss: 0.3596 - val_mse: 0.3530 - val_mae: 0.4025\n",
      "Epoch 235/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2464 - mse: 0.2399 - mae: 0.3438 - val_loss: 0.3583 - val_mse: 0.3517 - val_mae: 0.3956\n",
      "Epoch 236/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2455 - mse: 0.2389 - mae: 0.3436 - val_loss: 0.3580 - val_mse: 0.3514 - val_mae: 0.3974\n",
      "Epoch 237/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2453 - mse: 0.2387 - mae: 0.3423 - val_loss: 0.3542 - val_mse: 0.3476 - val_mae: 0.3938\n",
      "Epoch 238/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2438 - mse: 0.2372 - mae: 0.3408 - val_loss: 0.3574 - val_mse: 0.3508 - val_mae: 0.4007\n",
      "Epoch 239/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2431 - mse: 0.2365 - mae: 0.3415 - val_loss: 0.3544 - val_mse: 0.3477 - val_mae: 0.3923\n",
      "Epoch 240/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2439 - mse: 0.2372 - mae: 0.3413 - val_loss: 0.3565 - val_mse: 0.3499 - val_mae: 0.3979\n",
      "Epoch 241/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2420 - mse: 0.2353 - mae: 0.3402 - val_loss: 0.3507 - val_mse: 0.3440 - val_mae: 0.3891\n",
      "Epoch 242/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2411 - mse: 0.2344 - mae: 0.3381 - val_loss: 0.3518 - val_mse: 0.3451 - val_mae: 0.3947\n",
      "Epoch 243/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2404 - mse: 0.2337 - mae: 0.3395 - val_loss: 0.3521 - val_mse: 0.3454 - val_mae: 0.3902\n",
      "Epoch 244/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2391 - mse: 0.2324 - mae: 0.3377 - val_loss: 0.3514 - val_mse: 0.3447 - val_mae: 0.3915\n",
      "Epoch 245/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2370 - mse: 0.2303 - mae: 0.3349 - val_loss: 0.3479 - val_mse: 0.3412 - val_mae: 0.3903\n",
      "Epoch 246/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2373 - mse: 0.2305 - mae: 0.3349 - val_loss: 0.3496 - val_mse: 0.3429 - val_mae: 0.3934\n",
      "Epoch 247/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2349 - mse: 0.2282 - mae: 0.3344 - val_loss: 0.3461 - val_mse: 0.3394 - val_mae: 0.3867\n",
      "Epoch 248/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2362 - mse: 0.2295 - mae: 0.3328 - val_loss: 0.3497 - val_mse: 0.3429 - val_mae: 0.3956\n",
      "Epoch 249/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2329 - mse: 0.2261 - mae: 0.3334 - val_loss: 0.3434 - val_mse: 0.3367 - val_mae: 0.3848\n",
      "Epoch 250/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2328 - mse: 0.2260 - mae: 0.3307 - val_loss: 0.3477 - val_mse: 0.3410 - val_mae: 0.3958\n",
      "Epoch 251/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2320 - mse: 0.2252 - mae: 0.3338 - val_loss: 0.3410 - val_mse: 0.3342 - val_mae: 0.3815\n",
      "Epoch 252/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2320 - mse: 0.2252 - mae: 0.3313 - val_loss: 0.3439 - val_mse: 0.3371 - val_mae: 0.3892\n",
      "Epoch 253/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2284 - mse: 0.2216 - mae: 0.3278 - val_loss: 0.3385 - val_mse: 0.3316 - val_mae: 0.3823\n",
      "Epoch 254/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2318 - mse: 0.2250 - mae: 0.3319 - val_loss: 0.3398 - val_mse: 0.3330 - val_mae: 0.3837\n",
      "Epoch 255/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2285 - mse: 0.2216 - mae: 0.3264 - val_loss: 0.3377 - val_mse: 0.3309 - val_mae: 0.3886\n",
      "Epoch 256/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2267 - mse: 0.2199 - mae: 0.3303 - val_loss: 0.3325 - val_mse: 0.3257 - val_mae: 0.3784\n",
      "Epoch 257/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2267 - mse: 0.2198 - mae: 0.3268 - val_loss: 0.3419 - val_mse: 0.3350 - val_mae: 0.3939\n",
      "Epoch 258/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2257 - mse: 0.2189 - mae: 0.3282 - val_loss: 0.3327 - val_mse: 0.3258 - val_mae: 0.3781\n",
      "Epoch 259/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2237 - mse: 0.2168 - mae: 0.3246 - val_loss: 0.3358 - val_mse: 0.3288 - val_mae: 0.3877\n",
      "Epoch 260/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2243 - mse: 0.2174 - mae: 0.3264 - val_loss: 0.3317 - val_mse: 0.3247 - val_mae: 0.3819\n",
      "Epoch 261/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2229 - mse: 0.2160 - mae: 0.3272 - val_loss: 0.3275 - val_mse: 0.3206 - val_mae: 0.3761\n",
      "Epoch 262/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2229 - mse: 0.2159 - mae: 0.3237 - val_loss: 0.3337 - val_mse: 0.3268 - val_mae: 0.3883\n",
      "Epoch 263/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2204 - mse: 0.2134 - mae: 0.3232 - val_loss: 0.3264 - val_mse: 0.3195 - val_mae: 0.3766\n",
      "Epoch 264/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2214 - mse: 0.2144 - mae: 0.3248 - val_loss: 0.3292 - val_mse: 0.3222 - val_mae: 0.3768\n",
      "Epoch 265/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2196 - mse: 0.2126 - mae: 0.3204 - val_loss: 0.3271 - val_mse: 0.3201 - val_mae: 0.3832\n",
      "Epoch 266/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2181 - mse: 0.2111 - mae: 0.3213 - val_loss: 0.3266 - val_mse: 0.3196 - val_mae: 0.3775\n",
      "Epoch 267/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2181 - mse: 0.2111 - mae: 0.3210 - val_loss: 0.3235 - val_mse: 0.3165 - val_mae: 0.3773\n",
      "Epoch 268/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2180 - mse: 0.2109 - mae: 0.3202 - val_loss: 0.3271 - val_mse: 0.3201 - val_mae: 0.3765\n",
      "Epoch 269/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2186 - mse: 0.2116 - mae: 0.3182 - val_loss: 0.3306 - val_mse: 0.3236 - val_mae: 0.3893\n",
      "Epoch 270/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2172 - mse: 0.2102 - mae: 0.3223 - val_loss: 0.3220 - val_mse: 0.3149 - val_mae: 0.3734\n",
      "Epoch 271/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2159 - mse: 0.2089 - mae: 0.3202 - val_loss: 0.3230 - val_mse: 0.3159 - val_mae: 0.3773\n",
      "Epoch 272/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2153 - mse: 0.2083 - mae: 0.3205 - val_loss: 0.3164 - val_mse: 0.3094 - val_mae: 0.3692\n",
      "Epoch 273/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2136 - mse: 0.2065 - mae: 0.3161 - val_loss: 0.3262 - val_mse: 0.3191 - val_mae: 0.3828\n",
      "Epoch 274/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2114 - mse: 0.2043 - mae: 0.3167 - val_loss: 0.3188 - val_mse: 0.3117 - val_mae: 0.3721\n",
      "Epoch 275/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2115 - mse: 0.2043 - mae: 0.3144 - val_loss: 0.3185 - val_mse: 0.3114 - val_mae: 0.3693\n",
      "Epoch 276/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2100 - mse: 0.2029 - mae: 0.3124 - val_loss: 0.3207 - val_mse: 0.3135 - val_mae: 0.3794\n",
      "Epoch 277/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2088 - mse: 0.2016 - mae: 0.3139 - val_loss: 0.3206 - val_mse: 0.3134 - val_mae: 0.3705\n",
      "Epoch 278/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2082 - mse: 0.2010 - mae: 0.3119 - val_loss: 0.3146 - val_mse: 0.3074 - val_mae: 0.3685\n",
      "Epoch 279/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2071 - mse: 0.1999 - mae: 0.3097 - val_loss: 0.3207 - val_mse: 0.3135 - val_mae: 0.3804\n",
      "Epoch 280/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2064 - mse: 0.1992 - mae: 0.3100 - val_loss: 0.3166 - val_mse: 0.3094 - val_mae: 0.3692\n",
      "Epoch 281/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2048 - mse: 0.1976 - mae: 0.3079 - val_loss: 0.3152 - val_mse: 0.3080 - val_mae: 0.3716\n",
      "Epoch 282/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2037 - mse: 0.1965 - mae: 0.3090 - val_loss: 0.3142 - val_mse: 0.3070 - val_mae: 0.3690\n",
      "Epoch 283/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2041 - mse: 0.1968 - mae: 0.3073 - val_loss: 0.3161 - val_mse: 0.3088 - val_mae: 0.3691\n",
      "Epoch 284/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2043 - mse: 0.1971 - mae: 0.3072 - val_loss: 0.3065 - val_mse: 0.2992 - val_mae: 0.3658\n",
      "Epoch 285/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2030 - mse: 0.1957 - mae: 0.3075 - val_loss: 0.3121 - val_mse: 0.3048 - val_mae: 0.3636\n",
      "Epoch 286/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2017 - mse: 0.1945 - mae: 0.3066 - val_loss: 0.3106 - val_mse: 0.3033 - val_mae: 0.3676\n",
      "Epoch 287/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1999 - mse: 0.1926 - mae: 0.3047 - val_loss: 0.3087 - val_mse: 0.3014 - val_mae: 0.3638\n",
      "Epoch 288/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2000 - mse: 0.1927 - mae: 0.3062 - val_loss: 0.3131 - val_mse: 0.3058 - val_mae: 0.3759\n",
      "Epoch 289/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1994 - mse: 0.1921 - mae: 0.3039 - val_loss: 0.3078 - val_mse: 0.3005 - val_mae: 0.3688\n",
      "Epoch 290/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1977 - mse: 0.1904 - mae: 0.3028 - val_loss: 0.3088 - val_mse: 0.3014 - val_mae: 0.3696\n",
      "Epoch 291/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1972 - mse: 0.1899 - mae: 0.3034 - val_loss: 0.3069 - val_mse: 0.2996 - val_mae: 0.3678\n",
      "Epoch 292/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1963 - mse: 0.1889 - mae: 0.3035 - val_loss: 0.3013 - val_mse: 0.2939 - val_mae: 0.3554\n",
      "Epoch 293/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1960 - mse: 0.1886 - mae: 0.3010 - val_loss: 0.3121 - val_mse: 0.3047 - val_mae: 0.3814\n",
      "Epoch 294/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1974 - mse: 0.1900 - mae: 0.3051 - val_loss: 0.3061 - val_mse: 0.2988 - val_mae: 0.3690\n",
      "Epoch 295/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1943 - mse: 0.1869 - mae: 0.3027 - val_loss: 0.3010 - val_mse: 0.2936 - val_mae: 0.3543\n",
      "Epoch 296/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1941 - mse: 0.1867 - mae: 0.2994 - val_loss: 0.3029 - val_mse: 0.2954 - val_mae: 0.3637\n",
      "Epoch 297/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1923 - mse: 0.1849 - mae: 0.2985 - val_loss: 0.3017 - val_mse: 0.2943 - val_mae: 0.3717\n",
      "Epoch 298/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1918 - mse: 0.1844 - mae: 0.3002 - val_loss: 0.2982 - val_mse: 0.2908 - val_mae: 0.3530\n",
      "Epoch 299/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1904 - mse: 0.1830 - mae: 0.2961 - val_loss: 0.3049 - val_mse: 0.2974 - val_mae: 0.3749\n",
      "Epoch 300/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1921 - mse: 0.1846 - mae: 0.2992 - val_loss: 0.2978 - val_mse: 0.2903 - val_mae: 0.3590\n",
      "Epoch 301/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1888 - mse: 0.1813 - mae: 0.2974 - val_loss: 0.2968 - val_mse: 0.2893 - val_mae: 0.3576\n",
      "Epoch 302/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1899 - mse: 0.1824 - mae: 0.2964 - val_loss: 0.2999 - val_mse: 0.2924 - val_mae: 0.3579\n",
      "Epoch 303/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1911 - mse: 0.1836 - mae: 0.2984 - val_loss: 0.3047 - val_mse: 0.2972 - val_mae: 0.3787\n",
      "Epoch 304/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1873 - mse: 0.1798 - mae: 0.2957 - val_loss: 0.2924 - val_mse: 0.2848 - val_mae: 0.3528\n",
      "Epoch 305/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1868 - mse: 0.1793 - mae: 0.2950 - val_loss: 0.2946 - val_mse: 0.2871 - val_mae: 0.3577\n",
      "Epoch 306/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1865 - mse: 0.1790 - mae: 0.2937 - val_loss: 0.3030 - val_mse: 0.2954 - val_mae: 0.3772\n",
      "Epoch 307/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1847 - mse: 0.1771 - mae: 0.2942 - val_loss: 0.2873 - val_mse: 0.2797 - val_mae: 0.3475\n",
      "Epoch 308/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1864 - mse: 0.1788 - mae: 0.2958 - val_loss: 0.2965 - val_mse: 0.2889 - val_mae: 0.3667\n",
      "Epoch 309/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1831 - mse: 0.1755 - mae: 0.2914 - val_loss: 0.2891 - val_mse: 0.2816 - val_mae: 0.3553\n",
      "Epoch 310/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1821 - mse: 0.1745 - mae: 0.2904 - val_loss: 0.2921 - val_mse: 0.2845 - val_mae: 0.3617\n",
      "Epoch 311/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1847 - mse: 0.1771 - mae: 0.2927 - val_loss: 0.2837 - val_mse: 0.2761 - val_mae: 0.3472\n",
      "Epoch 312/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1822 - mse: 0.1745 - mae: 0.2923 - val_loss: 0.2849 - val_mse: 0.2772 - val_mae: 0.3469\n",
      "Epoch 313/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1809 - mse: 0.1732 - mae: 0.2894 - val_loss: 0.2883 - val_mse: 0.2807 - val_mae: 0.3626\n",
      "Epoch 314/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1796 - mse: 0.1720 - mae: 0.2881 - val_loss: 0.2808 - val_mse: 0.2731 - val_mae: 0.3465\n",
      "Epoch 315/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1789 - mse: 0.1712 - mae: 0.2874 - val_loss: 0.2912 - val_mse: 0.2836 - val_mae: 0.3631\n",
      "Epoch 316/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1771 - mse: 0.1694 - mae: 0.2855 - val_loss: 0.2825 - val_mse: 0.2749 - val_mae: 0.3469\n",
      "Epoch 317/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1780 - mse: 0.1703 - mae: 0.2870 - val_loss: 0.2783 - val_mse: 0.2706 - val_mae: 0.3464\n",
      "Epoch 318/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1774 - mse: 0.1697 - mae: 0.2881 - val_loss: 0.2791 - val_mse: 0.2714 - val_mae: 0.3497\n",
      "Epoch 319/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1773 - mse: 0.1696 - mae: 0.2867 - val_loss: 0.2862 - val_mse: 0.2784 - val_mae: 0.3558\n",
      "Epoch 320/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1749 - mse: 0.1672 - mae: 0.2835 - val_loss: 0.2762 - val_mse: 0.2685 - val_mae: 0.3439\n",
      "Epoch 321/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1743 - mse: 0.1665 - mae: 0.2840 - val_loss: 0.2800 - val_mse: 0.2723 - val_mae: 0.3561\n",
      "Epoch 322/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1744 - mse: 0.1666 - mae: 0.2852 - val_loss: 0.2760 - val_mse: 0.2683 - val_mae: 0.3459\n",
      "Epoch 323/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1738 - mse: 0.1660 - mae: 0.2837 - val_loss: 0.2735 - val_mse: 0.2657 - val_mae: 0.3467\n",
      "Epoch 324/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1723 - mse: 0.1645 - mae: 0.2855 - val_loss: 0.2742 - val_mse: 0.2664 - val_mae: 0.3487\n",
      "Epoch 325/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1721 - mse: 0.1643 - mae: 0.2825 - val_loss: 0.2736 - val_mse: 0.2658 - val_mae: 0.3444\n",
      "Epoch 326/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1705 - mse: 0.1627 - mae: 0.2805 - val_loss: 0.2761 - val_mse: 0.2683 - val_mae: 0.3488\n",
      "Epoch 327/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1696 - mse: 0.1618 - mae: 0.2806 - val_loss: 0.2709 - val_mse: 0.2631 - val_mae: 0.3463\n",
      "Epoch 328/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1700 - mse: 0.1622 - mae: 0.2814 - val_loss: 0.2691 - val_mse: 0.2612 - val_mae: 0.3450\n",
      "Epoch 329/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1684 - mse: 0.1605 - mae: 0.2802 - val_loss: 0.2678 - val_mse: 0.2599 - val_mae: 0.3422\n",
      "Epoch 330/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1683 - mse: 0.1604 - mae: 0.2793 - val_loss: 0.2671 - val_mse: 0.2592 - val_mae: 0.3463\n",
      "Epoch 331/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1685 - mse: 0.1606 - mae: 0.2813 - val_loss: 0.2669 - val_mse: 0.2590 - val_mae: 0.3405\n",
      "Epoch 332/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1678 - mse: 0.1600 - mae: 0.2800 - val_loss: 0.2616 - val_mse: 0.2537 - val_mae: 0.3335\n",
      "Epoch 333/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1657 - mse: 0.1578 - mae: 0.2758 - val_loss: 0.2716 - val_mse: 0.2637 - val_mae: 0.3557\n",
      "Epoch 334/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1646 - mse: 0.1567 - mae: 0.2775 - val_loss: 0.2598 - val_mse: 0.2519 - val_mae: 0.3304\n",
      "Epoch 335/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1655 - mse: 0.1575 - mae: 0.2756 - val_loss: 0.2752 - val_mse: 0.2672 - val_mae: 0.3577\n",
      "Epoch 336/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1639 - mse: 0.1559 - mae: 0.2747 - val_loss: 0.2593 - val_mse: 0.2513 - val_mae: 0.3363\n",
      "Epoch 337/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1624 - mse: 0.1544 - mae: 0.2734 - val_loss: 0.2648 - val_mse: 0.2568 - val_mae: 0.3400\n",
      "Epoch 338/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1627 - mse: 0.1547 - mae: 0.2741 - val_loss: 0.2622 - val_mse: 0.2542 - val_mae: 0.3452\n",
      "Epoch 339/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1620 - mse: 0.1540 - mae: 0.2751 - val_loss: 0.2585 - val_mse: 0.2505 - val_mae: 0.3369\n",
      "Epoch 340/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1610 - mse: 0.1529 - mae: 0.2726 - val_loss: 0.2649 - val_mse: 0.2569 - val_mae: 0.3461\n",
      "Epoch 341/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1607 - mse: 0.1527 - mae: 0.2728 - val_loss: 0.2576 - val_mse: 0.2496 - val_mae: 0.3399\n",
      "Epoch 342/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1584 - mse: 0.1503 - mae: 0.2701 - val_loss: 0.2578 - val_mse: 0.2498 - val_mae: 0.3330\n",
      "Epoch 343/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1587 - mse: 0.1507 - mae: 0.2719 - val_loss: 0.2580 - val_mse: 0.2499 - val_mae: 0.3391\n",
      "Epoch 344/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1584 - mse: 0.1503 - mae: 0.2702 - val_loss: 0.2529 - val_mse: 0.2449 - val_mae: 0.3394\n",
      "Epoch 345/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1566 - mse: 0.1485 - mae: 0.2708 - val_loss: 0.2558 - val_mse: 0.2477 - val_mae: 0.3401\n",
      "Epoch 346/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1560 - mse: 0.1479 - mae: 0.2682 - val_loss: 0.2507 - val_mse: 0.2426 - val_mae: 0.3281\n",
      "Epoch 347/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1564 - mse: 0.1483 - mae: 0.2684 - val_loss: 0.2522 - val_mse: 0.2441 - val_mae: 0.3318\n",
      "Epoch 348/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1552 - mse: 0.1471 - mae: 0.2665 - val_loss: 0.2569 - val_mse: 0.2488 - val_mae: 0.3448\n",
      "Epoch 349/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1552 - mse: 0.1470 - mae: 0.2680 - val_loss: 0.2483 - val_mse: 0.2401 - val_mae: 0.3351\n",
      "Epoch 350/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1541 - mse: 0.1459 - mae: 0.2659 - val_loss: 0.2573 - val_mse: 0.2492 - val_mae: 0.3431\n",
      "Epoch 351/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1555 - mse: 0.1473 - mae: 0.2697 - val_loss: 0.2473 - val_mse: 0.2391 - val_mae: 0.3254\n",
      "Epoch 352/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1539 - mse: 0.1457 - mae: 0.2680 - val_loss: 0.2444 - val_mse: 0.2363 - val_mae: 0.3341\n",
      "Epoch 353/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1520 - mse: 0.1439 - mae: 0.2670 - val_loss: 0.2458 - val_mse: 0.2376 - val_mae: 0.3220\n",
      "Epoch 354/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1509 - mse: 0.1427 - mae: 0.2620 - val_loss: 0.2487 - val_mse: 0.2405 - val_mae: 0.3357\n",
      "Epoch 355/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1504 - mse: 0.1422 - mae: 0.2632 - val_loss: 0.2434 - val_mse: 0.2351 - val_mae: 0.3300\n",
      "Epoch 356/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1486 - mse: 0.1403 - mae: 0.2618 - val_loss: 0.2395 - val_mse: 0.2312 - val_mae: 0.3248\n",
      "Epoch 357/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1483 - mse: 0.1400 - mae: 0.2619 - val_loss: 0.2444 - val_mse: 0.2362 - val_mae: 0.3330\n",
      "Epoch 358/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1482 - mse: 0.1399 - mae: 0.2606 - val_loss: 0.2444 - val_mse: 0.2362 - val_mae: 0.3335\n",
      "Epoch 359/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1481 - mse: 0.1398 - mae: 0.2597 - val_loss: 0.2401 - val_mse: 0.2318 - val_mae: 0.3170\n",
      "Epoch 360/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1499 - mse: 0.1416 - mae: 0.2641 - val_loss: 0.2366 - val_mse: 0.2283 - val_mae: 0.3251\n",
      "Epoch 361/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1458 - mse: 0.1375 - mae: 0.2582 - val_loss: 0.2459 - val_mse: 0.2376 - val_mae: 0.3355\n",
      "Epoch 362/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1449 - mse: 0.1366 - mae: 0.2555 - val_loss: 0.2377 - val_mse: 0.2294 - val_mae: 0.3258\n",
      "Epoch 363/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1445 - mse: 0.1362 - mae: 0.2563 - val_loss: 0.2388 - val_mse: 0.2304 - val_mae: 0.3248\n",
      "Epoch 364/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1433 - mse: 0.1349 - mae: 0.2542 - val_loss: 0.2395 - val_mse: 0.2312 - val_mae: 0.3267\n",
      "Epoch 365/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1424 - mse: 0.1341 - mae: 0.2556 - val_loss: 0.2324 - val_mse: 0.2241 - val_mae: 0.3219\n",
      "Epoch 366/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1412 - mse: 0.1328 - mae: 0.2531 - val_loss: 0.2322 - val_mse: 0.2239 - val_mae: 0.3183\n",
      "Epoch 367/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1414 - mse: 0.1330 - mae: 0.2532 - val_loss: 0.2318 - val_mse: 0.2234 - val_mae: 0.3146\n",
      "Epoch 368/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1424 - mse: 0.1340 - mae: 0.2546 - val_loss: 0.2283 - val_mse: 0.2199 - val_mae: 0.3195\n",
      "Epoch 369/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1404 - mse: 0.1319 - mae: 0.2502 - val_loss: 0.2358 - val_mse: 0.2274 - val_mae: 0.3218\n",
      "Epoch 370/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1390 - mse: 0.1306 - mae: 0.2497 - val_loss: 0.2247 - val_mse: 0.2163 - val_mae: 0.3128\n",
      "Epoch 371/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1386 - mse: 0.1301 - mae: 0.2517 - val_loss: 0.2300 - val_mse: 0.2215 - val_mae: 0.3214\n",
      "Epoch 372/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1371 - mse: 0.1287 - mae: 0.2470 - val_loss: 0.2260 - val_mse: 0.2175 - val_mae: 0.3155\n",
      "Epoch 373/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1374 - mse: 0.1289 - mae: 0.2481 - val_loss: 0.2334 - val_mse: 0.2249 - val_mae: 0.3285\n",
      "Epoch 374/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1381 - mse: 0.1296 - mae: 0.2501 - val_loss: 0.2305 - val_mse: 0.2220 - val_mae: 0.3205\n",
      "Epoch 375/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1365 - mse: 0.1280 - mae: 0.2469 - val_loss: 0.2259 - val_mse: 0.2174 - val_mae: 0.3133\n",
      "Epoch 376/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1347 - mse: 0.1262 - mae: 0.2436 - val_loss: 0.2264 - val_mse: 0.2179 - val_mae: 0.3173\n",
      "Epoch 377/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1363 - mse: 0.1278 - mae: 0.2475 - val_loss: 0.2269 - val_mse: 0.2184 - val_mae: 0.3245\n",
      "Epoch 378/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1342 - mse: 0.1257 - mae: 0.2453 - val_loss: 0.2231 - val_mse: 0.2146 - val_mae: 0.3140\n",
      "Epoch 379/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1332 - mse: 0.1246 - mae: 0.2438 - val_loss: 0.2165 - val_mse: 0.2079 - val_mae: 0.3084\n",
      "Epoch 380/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1325 - mse: 0.1240 - mae: 0.2428 - val_loss: 0.2186 - val_mse: 0.2100 - val_mae: 0.3145\n",
      "Epoch 381/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1329 - mse: 0.1243 - mae: 0.2432 - val_loss: 0.2212 - val_mse: 0.2126 - val_mae: 0.3129\n",
      "Epoch 382/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1315 - mse: 0.1229 - mae: 0.2414 - val_loss: 0.2163 - val_mse: 0.2077 - val_mae: 0.3071\n",
      "Epoch 383/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1309 - mse: 0.1223 - mae: 0.2405 - val_loss: 0.2158 - val_mse: 0.2072 - val_mae: 0.3116\n",
      "Epoch 384/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1303 - mse: 0.1217 - mae: 0.2410 - val_loss: 0.2149 - val_mse: 0.2062 - val_mae: 0.3066\n",
      "Epoch 385/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1294 - mse: 0.1208 - mae: 0.2394 - val_loss: 0.2152 - val_mse: 0.2066 - val_mae: 0.3096\n",
      "Epoch 386/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1290 - mse: 0.1204 - mae: 0.2394 - val_loss: 0.2155 - val_mse: 0.2069 - val_mae: 0.3126\n",
      "Epoch 387/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1300 - mse: 0.1213 - mae: 0.2416 - val_loss: 0.2139 - val_mse: 0.2052 - val_mae: 0.3136\n",
      "Epoch 388/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1302 - mse: 0.1215 - mae: 0.2409 - val_loss: 0.2151 - val_mse: 0.2064 - val_mae: 0.3058\n",
      "Epoch 389/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1281 - mse: 0.1194 - mae: 0.2382 - val_loss: 0.2084 - val_mse: 0.1997 - val_mae: 0.3070\n",
      "Epoch 390/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1270 - mse: 0.1183 - mae: 0.2375 - val_loss: 0.2074 - val_mse: 0.1987 - val_mae: 0.2956\n",
      "Epoch 391/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1284 - mse: 0.1197 - mae: 0.2410 - val_loss: 0.2042 - val_mse: 0.1955 - val_mae: 0.3021\n",
      "Epoch 392/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1260 - mse: 0.1172 - mae: 0.2371 - val_loss: 0.2088 - val_mse: 0.2001 - val_mae: 0.3095\n",
      "Epoch 393/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1257 - mse: 0.1170 - mae: 0.2371 - val_loss: 0.2050 - val_mse: 0.1962 - val_mae: 0.2953\n",
      "Epoch 394/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1261 - mse: 0.1174 - mae: 0.2368 - val_loss: 0.2127 - val_mse: 0.2039 - val_mae: 0.3144\n",
      "Epoch 395/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1258 - mse: 0.1170 - mae: 0.2359 - val_loss: 0.2028 - val_mse: 0.1940 - val_mae: 0.2986\n",
      "Epoch 396/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1241 - mse: 0.1154 - mae: 0.2341 - val_loss: 0.1998 - val_mse: 0.1910 - val_mae: 0.2952\n",
      "Epoch 397/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1231 - mse: 0.1143 - mae: 0.2333 - val_loss: 0.2010 - val_mse: 0.1922 - val_mae: 0.2946\n",
      "Epoch 398/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1223 - mse: 0.1135 - mae: 0.2334 - val_loss: 0.1997 - val_mse: 0.1908 - val_mae: 0.2977\n",
      "Epoch 399/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1223 - mse: 0.1135 - mae: 0.2328 - val_loss: 0.1988 - val_mse: 0.1900 - val_mae: 0.2987\n",
      "Epoch 400/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1210 - mse: 0.1122 - mae: 0.2322 - val_loss: 0.1992 - val_mse: 0.1903 - val_mae: 0.2997\n",
      "Epoch 401/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1209 - mse: 0.1120 - mae: 0.2311 - val_loss: 0.1962 - val_mse: 0.1874 - val_mae: 0.2922\n",
      "Epoch 402/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1214 - mse: 0.1125 - mae: 0.2325 - val_loss: 0.1955 - val_mse: 0.1867 - val_mae: 0.2938\n",
      "Epoch 403/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1211 - mse: 0.1122 - mae: 0.2327 - val_loss: 0.1995 - val_mse: 0.1906 - val_mae: 0.2996\n",
      "Epoch 404/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1201 - mse: 0.1112 - mae: 0.2306 - val_loss: 0.1944 - val_mse: 0.1855 - val_mae: 0.2887\n",
      "Epoch 405/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1206 - mse: 0.1117 - mae: 0.2323 - val_loss: 0.1994 - val_mse: 0.1905 - val_mae: 0.3030\n",
      "Epoch 406/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1188 - mse: 0.1099 - mae: 0.2303 - val_loss: 0.1904 - val_mse: 0.1815 - val_mae: 0.2951\n",
      "Epoch 407/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1194 - mse: 0.1104 - mae: 0.2317 - val_loss: 0.1937 - val_mse: 0.1847 - val_mae: 0.2946\n",
      "Epoch 408/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1181 - mse: 0.1091 - mae: 0.2303 - val_loss: 0.1915 - val_mse: 0.1825 - val_mae: 0.2962\n",
      "Epoch 409/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1168 - mse: 0.1078 - mae: 0.2273 - val_loss: 0.1908 - val_mse: 0.1819 - val_mae: 0.2933\n",
      "Epoch 410/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1166 - mse: 0.1076 - mae: 0.2278 - val_loss: 0.1877 - val_mse: 0.1788 - val_mae: 0.2869\n",
      "Epoch 411/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1171 - mse: 0.1081 - mae: 0.2301 - val_loss: 0.1868 - val_mse: 0.1778 - val_mae: 0.2825\n",
      "Epoch 412/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1157 - mse: 0.1067 - mae: 0.2268 - val_loss: 0.1929 - val_mse: 0.1839 - val_mae: 0.3009\n",
      "Epoch 413/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1161 - mse: 0.1071 - mae: 0.2276 - val_loss: 0.1865 - val_mse: 0.1775 - val_mae: 0.2875\n",
      "Epoch 414/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1151 - mse: 0.1061 - mae: 0.2258 - val_loss: 0.1832 - val_mse: 0.1742 - val_mae: 0.2842\n",
      "Epoch 415/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1156 - mse: 0.1066 - mae: 0.2287 - val_loss: 0.1836 - val_mse: 0.1746 - val_mae: 0.2889\n",
      "Epoch 416/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1137 - mse: 0.1047 - mae: 0.2263 - val_loss: 0.1858 - val_mse: 0.1768 - val_mae: 0.2900\n",
      "Epoch 417/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1139 - mse: 0.1048 - mae: 0.2248 - val_loss: 0.1890 - val_mse: 0.1800 - val_mae: 0.2972\n",
      "Epoch 418/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1141 - mse: 0.1050 - mae: 0.2254 - val_loss: 0.1794 - val_mse: 0.1704 - val_mae: 0.2783\n",
      "Epoch 419/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1135 - mse: 0.1044 - mae: 0.2249 - val_loss: 0.1815 - val_mse: 0.1724 - val_mae: 0.2787\n",
      "Epoch 420/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1145 - mse: 0.1054 - mae: 0.2279 - val_loss: 0.1830 - val_mse: 0.1740 - val_mae: 0.2884\n",
      "Epoch 421/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1130 - mse: 0.1039 - mae: 0.2253 - val_loss: 0.1815 - val_mse: 0.1724 - val_mae: 0.2874\n",
      "Epoch 422/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1120 - mse: 0.1029 - mae: 0.2234 - val_loss: 0.1887 - val_mse: 0.1796 - val_mae: 0.2996\n",
      "Epoch 423/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1118 - mse: 0.1027 - mae: 0.2233 - val_loss: 0.1804 - val_mse: 0.1712 - val_mae: 0.2852\n",
      "Epoch 424/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1107 - mse: 0.1016 - mae: 0.2228 - val_loss: 0.1735 - val_mse: 0.1644 - val_mae: 0.2774\n",
      "Epoch 425/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1107 - mse: 0.1016 - mae: 0.2219 - val_loss: 0.1790 - val_mse: 0.1699 - val_mae: 0.2804\n",
      "Epoch 426/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1107 - mse: 0.1016 - mae: 0.2238 - val_loss: 0.1742 - val_mse: 0.1651 - val_mae: 0.2817\n",
      "Epoch 427/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1111 - mse: 0.1020 - mae: 0.2246 - val_loss: 0.1747 - val_mse: 0.1655 - val_mae: 0.2787\n",
      "Epoch 428/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1104 - mse: 0.1012 - mae: 0.2225 - val_loss: 0.1757 - val_mse: 0.1666 - val_mae: 0.2782\n",
      "Epoch 429/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1094 - mse: 0.1002 - mae: 0.2228 - val_loss: 0.1745 - val_mse: 0.1653 - val_mae: 0.2836\n",
      "Epoch 430/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1090 - mse: 0.0998 - mae: 0.2218 - val_loss: 0.1773 - val_mse: 0.1681 - val_mae: 0.2879\n",
      "Epoch 431/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1088 - mse: 0.0996 - mae: 0.2228 - val_loss: 0.1721 - val_mse: 0.1629 - val_mae: 0.2797\n",
      "Epoch 432/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1077 - mse: 0.0985 - mae: 0.2209 - val_loss: 0.1725 - val_mse: 0.1633 - val_mae: 0.2822\n",
      "Epoch 433/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1084 - mse: 0.0992 - mae: 0.2208 - val_loss: 0.1728 - val_mse: 0.1636 - val_mae: 0.2780\n",
      "Epoch 434/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1082 - mse: 0.0989 - mae: 0.2220 - val_loss: 0.1699 - val_mse: 0.1606 - val_mae: 0.2711\n",
      "Epoch 435/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1077 - mse: 0.0985 - mae: 0.2215 - val_loss: 0.1749 - val_mse: 0.1657 - val_mae: 0.2907\n",
      "Epoch 436/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1067 - mse: 0.0975 - mae: 0.2193 - val_loss: 0.1709 - val_mse: 0.1617 - val_mae: 0.2814\n",
      "Epoch 437/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1066 - mse: 0.0974 - mae: 0.2193 - val_loss: 0.1655 - val_mse: 0.1563 - val_mae: 0.2749\n",
      "Epoch 438/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1064 - mse: 0.0972 - mae: 0.2188 - val_loss: 0.1705 - val_mse: 0.1612 - val_mae: 0.2760\n",
      "Epoch 439/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1073 - mse: 0.0980 - mae: 0.2190 - val_loss: 0.1651 - val_mse: 0.1558 - val_mae: 0.2685\n",
      "Epoch 440/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1070 - mse: 0.0977 - mae: 0.2225 - val_loss: 0.1682 - val_mse: 0.1589 - val_mae: 0.2748\n",
      "Epoch 441/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1066 - mse: 0.0973 - mae: 0.2194 - val_loss: 0.1616 - val_mse: 0.1523 - val_mae: 0.2678\n",
      "Epoch 442/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1055 - mse: 0.0962 - mae: 0.2198 - val_loss: 0.1677 - val_mse: 0.1583 - val_mae: 0.2794\n",
      "Epoch 443/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1054 - mse: 0.0961 - mae: 0.2217 - val_loss: 0.1644 - val_mse: 0.1550 - val_mae: 0.2763\n",
      "Epoch 444/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1042 - mse: 0.0949 - mae: 0.2189 - val_loss: 0.1640 - val_mse: 0.1547 - val_mae: 0.2752\n",
      "Epoch 445/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1037 - mse: 0.0944 - mae: 0.2169 - val_loss: 0.1627 - val_mse: 0.1533 - val_mae: 0.2674\n",
      "Epoch 446/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1033 - mse: 0.0940 - mae: 0.2145 - val_loss: 0.1648 - val_mse: 0.1555 - val_mae: 0.2761\n",
      "Epoch 447/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1030 - mse: 0.0937 - mae: 0.2159 - val_loss: 0.1659 - val_mse: 0.1566 - val_mae: 0.2825\n",
      "Epoch 448/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1024 - mse: 0.0930 - mae: 0.2171 - val_loss: 0.1604 - val_mse: 0.1511 - val_mae: 0.2750\n",
      "Epoch 449/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1029 - mse: 0.0935 - mae: 0.2161 - val_loss: 0.1620 - val_mse: 0.1527 - val_mae: 0.2708\n",
      "Epoch 450/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1036 - mse: 0.0942 - mae: 0.2174 - val_loss: 0.1546 - val_mse: 0.1452 - val_mae: 0.2578\n",
      "Epoch 451/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1031 - mse: 0.0937 - mae: 0.2154 - val_loss: 0.1630 - val_mse: 0.1536 - val_mae: 0.2760\n",
      "Epoch 452/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1027 - mse: 0.0933 - mae: 0.2187 - val_loss: 0.1673 - val_mse: 0.1579 - val_mae: 0.2912\n",
      "Epoch 453/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1030 - mse: 0.0936 - mae: 0.2191 - val_loss: 0.1550 - val_mse: 0.1456 - val_mae: 0.2659\n",
      "Epoch 454/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1029 - mse: 0.0935 - mae: 0.2168 - val_loss: 0.1575 - val_mse: 0.1481 - val_mae: 0.2632\n",
      "Epoch 455/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1038 - mse: 0.0944 - mae: 0.2173 - val_loss: 0.1553 - val_mse: 0.1458 - val_mae: 0.2651\n",
      "Epoch 456/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1013 - mse: 0.0919 - mae: 0.2157 - val_loss: 0.1551 - val_mse: 0.1456 - val_mae: 0.2726\n",
      "Epoch 457/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0994 - mse: 0.0899 - mae: 0.2133 - val_loss: 0.1551 - val_mse: 0.1457 - val_mae: 0.2668\n",
      "Epoch 458/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0995 - mse: 0.0900 - mae: 0.2125 - val_loss: 0.1575 - val_mse: 0.1481 - val_mae: 0.2659\n",
      "Epoch 459/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0999 - mse: 0.0905 - mae: 0.2134 - val_loss: 0.1509 - val_mse: 0.1415 - val_mae: 0.2608\n",
      "Epoch 460/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0990 - mse: 0.0895 - mae: 0.2142 - val_loss: 0.1587 - val_mse: 0.1492 - val_mae: 0.2782\n",
      "Epoch 461/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0990 - mse: 0.0896 - mae: 0.2145 - val_loss: 0.1532 - val_mse: 0.1437 - val_mae: 0.2704\n",
      "Epoch 462/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0991 - mse: 0.0896 - mae: 0.2134 - val_loss: 0.1579 - val_mse: 0.1484 - val_mae: 0.2742\n",
      "Epoch 463/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0992 - mse: 0.0897 - mae: 0.2158 - val_loss: 0.1503 - val_mse: 0.1408 - val_mae: 0.2625\n",
      "Epoch 464/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0992 - mse: 0.0897 - mae: 0.2151 - val_loss: 0.1462 - val_mse: 0.1367 - val_mae: 0.2550\n",
      "Epoch 465/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1004 - mse: 0.0908 - mae: 0.2132 - val_loss: 0.1525 - val_mse: 0.1429 - val_mae: 0.2667\n",
      "Epoch 466/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1000 - mse: 0.0905 - mae: 0.2164 - val_loss: 0.1571 - val_mse: 0.1476 - val_mae: 0.2757\n",
      "Epoch 467/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0972 - mse: 0.0877 - mae: 0.2101 - val_loss: 0.1464 - val_mse: 0.1369 - val_mae: 0.2627\n",
      "Epoch 468/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0981 - mse: 0.0886 - mae: 0.2131 - val_loss: 0.1479 - val_mse: 0.1383 - val_mae: 0.2589\n",
      "Epoch 469/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0980 - mse: 0.0884 - mae: 0.2121 - val_loss: 0.1492 - val_mse: 0.1396 - val_mae: 0.2655\n",
      "Epoch 470/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0975 - mse: 0.0879 - mae: 0.2117 - val_loss: 0.1544 - val_mse: 0.1448 - val_mae: 0.2731\n",
      "Epoch 471/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0979 - mse: 0.0883 - mae: 0.2137 - val_loss: 0.1556 - val_mse: 0.1460 - val_mae: 0.2797\n",
      "Epoch 472/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0975 - mse: 0.0879 - mae: 0.2115 - val_loss: 0.1441 - val_mse: 0.1345 - val_mae: 0.2595\n",
      "Epoch 473/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0956 - mse: 0.0860 - mae: 0.2103 - val_loss: 0.1459 - val_mse: 0.1363 - val_mae: 0.2583\n",
      "Epoch 474/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0959 - mse: 0.0863 - mae: 0.2097 - val_loss: 0.1474 - val_mse: 0.1378 - val_mae: 0.2644\n",
      "Epoch 475/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0955 - mse: 0.0859 - mae: 0.2089 - val_loss: 0.1409 - val_mse: 0.1312 - val_mae: 0.2591\n",
      "Epoch 476/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0946 - mse: 0.0850 - mae: 0.2100 - val_loss: 0.1479 - val_mse: 0.1383 - val_mae: 0.2694\n",
      "Epoch 477/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0947 - mse: 0.0850 - mae: 0.2087 - val_loss: 0.1422 - val_mse: 0.1326 - val_mae: 0.2587\n",
      "Epoch 478/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0939 - mse: 0.0843 - mae: 0.2063 - val_loss: 0.1412 - val_mse: 0.1316 - val_mae: 0.2555\n",
      "Epoch 479/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0956 - mse: 0.0860 - mae: 0.2111 - val_loss: 0.1406 - val_mse: 0.1310 - val_mae: 0.2564\n",
      "Epoch 480/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0943 - mse: 0.0847 - mae: 0.2103 - val_loss: 0.1455 - val_mse: 0.1359 - val_mae: 0.2657\n",
      "Epoch 481/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0936 - mse: 0.0840 - mae: 0.2062 - val_loss: 0.1393 - val_mse: 0.1297 - val_mae: 0.2521\n",
      "Epoch 482/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0939 - mse: 0.0842 - mae: 0.2074 - val_loss: 0.1454 - val_mse: 0.1357 - val_mae: 0.2610\n",
      "Epoch 483/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0938 - mse: 0.0841 - mae: 0.2077 - val_loss: 0.1403 - val_mse: 0.1306 - val_mae: 0.2564\n",
      "Epoch 484/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0928 - mse: 0.0831 - mae: 0.2057 - val_loss: 0.1416 - val_mse: 0.1319 - val_mae: 0.2574\n",
      "Epoch 485/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0928 - mse: 0.0831 - mae: 0.2071 - val_loss: 0.1404 - val_mse: 0.1307 - val_mae: 0.2596\n",
      "Epoch 486/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0929 - mse: 0.0832 - mae: 0.2069 - val_loss: 0.1440 - val_mse: 0.1343 - val_mae: 0.2653\n",
      "Epoch 487/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0925 - mse: 0.0828 - mae: 0.2059 - val_loss: 0.1390 - val_mse: 0.1293 - val_mae: 0.2496\n",
      "Epoch 488/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0930 - mse: 0.0833 - mae: 0.2074 - val_loss: 0.1444 - val_mse: 0.1347 - val_mae: 0.2671\n",
      "Epoch 489/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0929 - mse: 0.0832 - mae: 0.2078 - val_loss: 0.1440 - val_mse: 0.1342 - val_mae: 0.2625\n",
      "Epoch 490/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0923 - mse: 0.0826 - mae: 0.2064 - val_loss: 0.1353 - val_mse: 0.1256 - val_mae: 0.2521\n",
      "Epoch 491/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0913 - mse: 0.0816 - mae: 0.2056 - val_loss: 0.1382 - val_mse: 0.1284 - val_mae: 0.2560\n",
      "Epoch 492/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0912 - mse: 0.0815 - mae: 0.2047 - val_loss: 0.1402 - val_mse: 0.1304 - val_mae: 0.2595\n",
      "Epoch 493/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0917 - mse: 0.0820 - mae: 0.2034 - val_loss: 0.1429 - val_mse: 0.1331 - val_mae: 0.2656\n",
      "Epoch 494/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0919 - mse: 0.0822 - mae: 0.2063 - val_loss: 0.1318 - val_mse: 0.1221 - val_mae: 0.2474\n",
      "Epoch 495/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0907 - mse: 0.0809 - mae: 0.2053 - val_loss: 0.1390 - val_mse: 0.1292 - val_mae: 0.2570\n",
      "Epoch 496/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0917 - mse: 0.0819 - mae: 0.2065 - val_loss: 0.1377 - val_mse: 0.1280 - val_mae: 0.2592\n",
      "Epoch 497/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0906 - mse: 0.0808 - mae: 0.2037 - val_loss: 0.1323 - val_mse: 0.1225 - val_mae: 0.2504\n",
      "Epoch 498/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0904 - mse: 0.0807 - mae: 0.2042 - val_loss: 0.1324 - val_mse: 0.1227 - val_mae: 0.2502\n",
      "Epoch 499/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0907 - mse: 0.0809 - mae: 0.2048 - val_loss: 0.1377 - val_mse: 0.1279 - val_mae: 0.2594\n",
      "Epoch 500/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0901 - mse: 0.0803 - mae: 0.2054 - val_loss: 0.1359 - val_mse: 0.1261 - val_mae: 0.2581\n",
      "Epoch 501/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0893 - mse: 0.0795 - mae: 0.2038 - val_loss: 0.1337 - val_mse: 0.1239 - val_mae: 0.2510\n",
      "Epoch 502/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0892 - mse: 0.0794 - mae: 0.2013 - val_loss: 0.1367 - val_mse: 0.1269 - val_mae: 0.2537\n",
      "Epoch 503/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0893 - mse: 0.0795 - mae: 0.2045 - val_loss: 0.1379 - val_mse: 0.1281 - val_mae: 0.2613\n",
      "Epoch 504/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0895 - mse: 0.0797 - mae: 0.2034 - val_loss: 0.1314 - val_mse: 0.1216 - val_mae: 0.2519\n",
      "Epoch 505/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0890 - mse: 0.0792 - mae: 0.2033 - val_loss: 0.1363 - val_mse: 0.1265 - val_mae: 0.2564\n",
      "Epoch 506/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0884 - mse: 0.0786 - mae: 0.2026 - val_loss: 0.1337 - val_mse: 0.1238 - val_mae: 0.2532\n",
      "Epoch 507/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0904 - mse: 0.0805 - mae: 0.2060 - val_loss: 0.1371 - val_mse: 0.1273 - val_mae: 0.2568\n",
      "Epoch 508/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0898 - mse: 0.0799 - mae: 0.2061 - val_loss: 0.1345 - val_mse: 0.1247 - val_mae: 0.2555\n",
      "Epoch 509/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0891 - mse: 0.0792 - mae: 0.2031 - val_loss: 0.1284 - val_mse: 0.1186 - val_mae: 0.2473\n",
      "Epoch 510/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0878 - mse: 0.0780 - mae: 0.2020 - val_loss: 0.1335 - val_mse: 0.1236 - val_mae: 0.2541\n",
      "Epoch 511/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0877 - mse: 0.0779 - mae: 0.2021 - val_loss: 0.1314 - val_mse: 0.1215 - val_mae: 0.2486\n",
      "Epoch 512/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0878 - mse: 0.0779 - mae: 0.2025 - val_loss: 0.1307 - val_mse: 0.1208 - val_mae: 0.2470\n",
      "Epoch 513/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0873 - mse: 0.0775 - mae: 0.2003 - val_loss: 0.1311 - val_mse: 0.1212 - val_mae: 0.2468\n",
      "Epoch 514/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0872 - mse: 0.0773 - mae: 0.2025 - val_loss: 0.1259 - val_mse: 0.1160 - val_mae: 0.2431\n",
      "Epoch 515/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0877 - mse: 0.0778 - mae: 0.2013 - val_loss: 0.1362 - val_mse: 0.1263 - val_mae: 0.2525\n",
      "Epoch 516/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0868 - mse: 0.0769 - mae: 0.2020 - val_loss: 0.1282 - val_mse: 0.1183 - val_mae: 0.2506\n",
      "Epoch 517/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0860 - mse: 0.0761 - mae: 0.1997 - val_loss: 0.1288 - val_mse: 0.1189 - val_mae: 0.2486\n",
      "Epoch 518/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0866 - mse: 0.0767 - mae: 0.2022 - val_loss: 0.1282 - val_mse: 0.1183 - val_mae: 0.2457\n",
      "Epoch 519/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0867 - mse: 0.0768 - mae: 0.2011 - val_loss: 0.1308 - val_mse: 0.1208 - val_mae: 0.2471\n",
      "Epoch 520/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0862 - mse: 0.0762 - mae: 0.1995 - val_loss: 0.1241 - val_mse: 0.1142 - val_mae: 0.2398\n",
      "Epoch 521/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0858 - mse: 0.0759 - mae: 0.2003 - val_loss: 0.1251 - val_mse: 0.1152 - val_mae: 0.2444\n",
      "Epoch 522/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0856 - mse: 0.0756 - mae: 0.2000 - val_loss: 0.1257 - val_mse: 0.1158 - val_mae: 0.2442\n",
      "Epoch 523/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0857 - mse: 0.0758 - mae: 0.2008 - val_loss: 0.1239 - val_mse: 0.1140 - val_mae: 0.2415\n",
      "Epoch 524/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0846 - mse: 0.0747 - mae: 0.1990 - val_loss: 0.1316 - val_mse: 0.1216 - val_mae: 0.2563\n",
      "Epoch 525/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0852 - mse: 0.0753 - mae: 0.1982 - val_loss: 0.1287 - val_mse: 0.1188 - val_mae: 0.2491\n",
      "Epoch 526/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0846 - mse: 0.0746 - mae: 0.1975 - val_loss: 0.1285 - val_mse: 0.1186 - val_mae: 0.2468\n",
      "Epoch 527/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0853 - mse: 0.0753 - mae: 0.1996 - val_loss: 0.1199 - val_mse: 0.1100 - val_mae: 0.2336\n",
      "Epoch 528/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0869 - mse: 0.0769 - mae: 0.2054 - val_loss: 0.1227 - val_mse: 0.1127 - val_mae: 0.2370\n",
      "Epoch 529/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0879 - mse: 0.0779 - mae: 0.2036 - val_loss: 0.1247 - val_mse: 0.1147 - val_mae: 0.2388\n",
      "Epoch 530/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0864 - mse: 0.0764 - mae: 0.2016 - val_loss: 0.1263 - val_mse: 0.1163 - val_mae: 0.2501\n",
      "Epoch 531/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0847 - mse: 0.0747 - mae: 0.1994 - val_loss: 0.1249 - val_mse: 0.1149 - val_mae: 0.2463\n",
      "Epoch 532/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0832 - mse: 0.0732 - mae: 0.1969 - val_loss: 0.1205 - val_mse: 0.1105 - val_mae: 0.2386\n",
      "Epoch 533/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0843 - mse: 0.0743 - mae: 0.1982 - val_loss: 0.1218 - val_mse: 0.1118 - val_mae: 0.2363\n",
      "Epoch 534/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0863 - mse: 0.0763 - mae: 0.2042 - val_loss: 0.1183 - val_mse: 0.1082 - val_mae: 0.2327\n",
      "Epoch 535/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0831 - mse: 0.0731 - mae: 0.1979 - val_loss: 0.1282 - val_mse: 0.1181 - val_mae: 0.2546\n",
      "Epoch 536/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0831 - mse: 0.0731 - mae: 0.1973 - val_loss: 0.1219 - val_mse: 0.1118 - val_mae: 0.2405\n",
      "Epoch 537/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0828 - mse: 0.0728 - mae: 0.1966 - val_loss: 0.1256 - val_mse: 0.1156 - val_mae: 0.2500\n",
      "Epoch 538/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0838 - mse: 0.0738 - mae: 0.2000 - val_loss: 0.1249 - val_mse: 0.1148 - val_mae: 0.2422\n",
      "Epoch 539/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0828 - mse: 0.0727 - mae: 0.1968 - val_loss: 0.1176 - val_mse: 0.1075 - val_mae: 0.2363\n",
      "Epoch 540/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0827 - mse: 0.0726 - mae: 0.1971 - val_loss: 0.1217 - val_mse: 0.1117 - val_mae: 0.2383\n",
      "Epoch 541/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0829 - mse: 0.0729 - mae: 0.1971 - val_loss: 0.1205 - val_mse: 0.1104 - val_mae: 0.2435\n",
      "Epoch 542/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0816 - mse: 0.0716 - mae: 0.1956 - val_loss: 0.1225 - val_mse: 0.1124 - val_mae: 0.2434\n",
      "Epoch 543/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0831 - mse: 0.0731 - mae: 0.1984 - val_loss: 0.1207 - val_mse: 0.1107 - val_mae: 0.2432\n",
      "Epoch 544/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0847 - mse: 0.0746 - mae: 0.2032 - val_loss: 0.1225 - val_mse: 0.1124 - val_mae: 0.2421\n",
      "Epoch 545/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0813 - mse: 0.0712 - mae: 0.1944 - val_loss: 0.1144 - val_mse: 0.1044 - val_mae: 0.2305\n",
      "Epoch 546/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0833 - mse: 0.0732 - mae: 0.1976 - val_loss: 0.1221 - val_mse: 0.1120 - val_mae: 0.2462\n",
      "Epoch 547/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0812 - mse: 0.0711 - mae: 0.1960 - val_loss: 0.1266 - val_mse: 0.1165 - val_mae: 0.2531\n",
      "Epoch 548/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0835 - mse: 0.0734 - mae: 0.2009 - val_loss: 0.1185 - val_mse: 0.1084 - val_mae: 0.2401\n",
      "Epoch 549/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0826 - mse: 0.0725 - mae: 0.2002 - val_loss: 0.1238 - val_mse: 0.1137 - val_mae: 0.2495\n",
      "Epoch 550/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0829 - mse: 0.0728 - mae: 0.1971 - val_loss: 0.1194 - val_mse: 0.1093 - val_mae: 0.2437\n",
      "Epoch 551/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0820 - mse: 0.0718 - mae: 0.1997 - val_loss: 0.1230 - val_mse: 0.1129 - val_mae: 0.2427\n",
      "Epoch 552/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0813 - mse: 0.0712 - mae: 0.1976 - val_loss: 0.1253 - val_mse: 0.1152 - val_mae: 0.2539\n",
      "Epoch 553/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0826 - mse: 0.0725 - mae: 0.1981 - val_loss: 0.1162 - val_mse: 0.1060 - val_mae: 0.2372\n",
      "Epoch 554/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0799 - mse: 0.0697 - mae: 0.1922 - val_loss: 0.1163 - val_mse: 0.1062 - val_mae: 0.2370\n",
      "Epoch 555/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0801 - mse: 0.0700 - mae: 0.1948 - val_loss: 0.1156 - val_mse: 0.1055 - val_mae: 0.2343\n",
      "Epoch 556/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0826 - mse: 0.0725 - mae: 0.1968 - val_loss: 0.1236 - val_mse: 0.1135 - val_mae: 0.2521\n",
      "Epoch 557/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0823 - mse: 0.0721 - mae: 0.1992 - val_loss: 0.1217 - val_mse: 0.1116 - val_mae: 0.2452\n",
      "Epoch 558/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0814 - mse: 0.0712 - mae: 0.1957 - val_loss: 0.1205 - val_mse: 0.1104 - val_mae: 0.2448\n",
      "Epoch 559/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0800 - mse: 0.0698 - mae: 0.1942 - val_loss: 0.1175 - val_mse: 0.1073 - val_mae: 0.2424\n",
      "Epoch 560/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0806 - mse: 0.0704 - mae: 0.1980 - val_loss: 0.1205 - val_mse: 0.1104 - val_mae: 0.2392\n",
      "Epoch 561/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0804 - mse: 0.0702 - mae: 0.1944 - val_loss: 0.1136 - val_mse: 0.1034 - val_mae: 0.2338\n",
      "Epoch 562/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0795 - mse: 0.0693 - mae: 0.1931 - val_loss: 0.1183 - val_mse: 0.1081 - val_mae: 0.2437\n",
      "Epoch 563/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0804 - mse: 0.0702 - mae: 0.1939 - val_loss: 0.1117 - val_mse: 0.1015 - val_mae: 0.2331\n",
      "Epoch 564/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0795 - mse: 0.0694 - mae: 0.1952 - val_loss: 0.1121 - val_mse: 0.1019 - val_mae: 0.2259\n",
      "Epoch 565/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0785 - mse: 0.0684 - mae: 0.1914 - val_loss: 0.1135 - val_mse: 0.1033 - val_mae: 0.2300\n",
      "Epoch 566/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0788 - mse: 0.0686 - mae: 0.1935 - val_loss: 0.1095 - val_mse: 0.0994 - val_mae: 0.2294\n",
      "Epoch 567/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0789 - mse: 0.0687 - mae: 0.1938 - val_loss: 0.1138 - val_mse: 0.1036 - val_mae: 0.2386\n",
      "Epoch 568/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0794 - mse: 0.0692 - mae: 0.1955 - val_loss: 0.1181 - val_mse: 0.1079 - val_mae: 0.2396\n",
      "Epoch 569/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0799 - mse: 0.0697 - mae: 0.1965 - val_loss: 0.1132 - val_mse: 0.1030 - val_mae: 0.2363\n",
      "Epoch 570/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0796 - mse: 0.0694 - mae: 0.1944 - val_loss: 0.1087 - val_mse: 0.0985 - val_mae: 0.2274\n",
      "Epoch 571/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0792 - mse: 0.0690 - mae: 0.1933 - val_loss: 0.1096 - val_mse: 0.0994 - val_mae: 0.2280\n",
      "Epoch 572/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0779 - mse: 0.0677 - mae: 0.1931 - val_loss: 0.1123 - val_mse: 0.1021 - val_mae: 0.2295\n",
      "Epoch 573/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0782 - mse: 0.0680 - mae: 0.1933 - val_loss: 0.1093 - val_mse: 0.0990 - val_mae: 0.2218\n",
      "Epoch 574/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0790 - mse: 0.0688 - mae: 0.1938 - val_loss: 0.1060 - val_mse: 0.0958 - val_mae: 0.2230\n",
      "Epoch 575/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0775 - mse: 0.0673 - mae: 0.1918 - val_loss: 0.1087 - val_mse: 0.0984 - val_mae: 0.2253\n",
      "Epoch 576/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0779 - mse: 0.0676 - mae: 0.1918 - val_loss: 0.1106 - val_mse: 0.1004 - val_mae: 0.2276\n",
      "Epoch 577/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0766 - mse: 0.0664 - mae: 0.1905 - val_loss: 0.1117 - val_mse: 0.1015 - val_mae: 0.2347\n",
      "Epoch 578/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0766 - mse: 0.0664 - mae: 0.1898 - val_loss: 0.1076 - val_mse: 0.0973 - val_mae: 0.2250\n",
      "Epoch 579/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0768 - mse: 0.0666 - mae: 0.1906 - val_loss: 0.1043 - val_mse: 0.0940 - val_mae: 0.2200\n",
      "Epoch 580/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0767 - mse: 0.0665 - mae: 0.1908 - val_loss: 0.1054 - val_mse: 0.0952 - val_mae: 0.2207\n",
      "Epoch 581/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0767 - mse: 0.0665 - mae: 0.1918 - val_loss: 0.1089 - val_mse: 0.0986 - val_mae: 0.2307\n",
      "Epoch 582/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0769 - mse: 0.0667 - mae: 0.1904 - val_loss: 0.1093 - val_mse: 0.0990 - val_mae: 0.2312\n",
      "Epoch 583/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0767 - mse: 0.0664 - mae: 0.1894 - val_loss: 0.1087 - val_mse: 0.0984 - val_mae: 0.2318\n",
      "Epoch 584/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0771 - mse: 0.0669 - mae: 0.1921 - val_loss: 0.1100 - val_mse: 0.0997 - val_mae: 0.2318\n",
      "Epoch 585/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0769 - mse: 0.0666 - mae: 0.1905 - val_loss: 0.1092 - val_mse: 0.0989 - val_mae: 0.2309\n",
      "Epoch 586/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0769 - mse: 0.0666 - mae: 0.1915 - val_loss: 0.1065 - val_mse: 0.0963 - val_mae: 0.2229\n",
      "Epoch 587/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0765 - mse: 0.0663 - mae: 0.1913 - val_loss: 0.1058 - val_mse: 0.0955 - val_mae: 0.2303\n",
      "Epoch 588/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0751 - mse: 0.0648 - mae: 0.1884 - val_loss: 0.1038 - val_mse: 0.0935 - val_mae: 0.2119\n",
      "Epoch 589/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0773 - mse: 0.0670 - mae: 0.1935 - val_loss: 0.1057 - val_mse: 0.0954 - val_mae: 0.2282\n",
      "Epoch 590/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0758 - mse: 0.0656 - mae: 0.1920 - val_loss: 0.1054 - val_mse: 0.0951 - val_mae: 0.2209\n",
      "Epoch 591/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0758 - mse: 0.0655 - mae: 0.1892 - val_loss: 0.0997 - val_mse: 0.0894 - val_mae: 0.2151\n",
      "Epoch 592/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0758 - mse: 0.0655 - mae: 0.1908 - val_loss: 0.1066 - val_mse: 0.0963 - val_mae: 0.2259\n",
      "Epoch 593/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0766 - mse: 0.0663 - mae: 0.1910 - val_loss: 0.1092 - val_mse: 0.0989 - val_mae: 0.2327\n",
      "Epoch 594/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0759 - mse: 0.0656 - mae: 0.1897 - val_loss: 0.1108 - val_mse: 0.1005 - val_mae: 0.2357\n",
      "Epoch 595/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0762 - mse: 0.0658 - mae: 0.1917 - val_loss: 0.1018 - val_mse: 0.0915 - val_mae: 0.2159\n",
      "Epoch 596/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0768 - mse: 0.0665 - mae: 0.1917 - val_loss: 0.1018 - val_mse: 0.0914 - val_mae: 0.2160\n",
      "Epoch 597/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0747 - mse: 0.0643 - mae: 0.1875 - val_loss: 0.1058 - val_mse: 0.0955 - val_mae: 0.2304\n",
      "Epoch 598/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0749 - mse: 0.0645 - mae: 0.1888 - val_loss: 0.1058 - val_mse: 0.0955 - val_mae: 0.2284\n",
      "Epoch 599/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0762 - mse: 0.0659 - mae: 0.1897 - val_loss: 0.1037 - val_mse: 0.0934 - val_mae: 0.2243\n",
      "Epoch 600/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0755 - mse: 0.0651 - mae: 0.1937 - val_loss: 0.1066 - val_mse: 0.0963 - val_mae: 0.2295\n",
      "Epoch 601/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0753 - mse: 0.0650 - mae: 0.1914 - val_loss: 0.1044 - val_mse: 0.0941 - val_mae: 0.2292\n",
      "Epoch 602/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0755 - mse: 0.0651 - mae: 0.1904 - val_loss: 0.1065 - val_mse: 0.0962 - val_mae: 0.2290\n",
      "Epoch 603/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0760 - mse: 0.0657 - mae: 0.1921 - val_loss: 0.1021 - val_mse: 0.0917 - val_mae: 0.2219\n",
      "Epoch 604/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0755 - mse: 0.0652 - mae: 0.1909 - val_loss: 0.1010 - val_mse: 0.0906 - val_mae: 0.2157\n",
      "Epoch 605/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0736 - mse: 0.0632 - mae: 0.1860 - val_loss: 0.0972 - val_mse: 0.0868 - val_mae: 0.2104\n",
      "Epoch 606/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0772 - mse: 0.0668 - mae: 0.1951 - val_loss: 0.0994 - val_mse: 0.0890 - val_mae: 0.2084\n",
      "Epoch 607/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0782 - mse: 0.0678 - mae: 0.1964 - val_loss: 0.1034 - val_mse: 0.0931 - val_mae: 0.2258\n",
      "Epoch 608/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0746 - mse: 0.0642 - mae: 0.1907 - val_loss: 0.1078 - val_mse: 0.0974 - val_mae: 0.2331\n",
      "Epoch 609/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0743 - mse: 0.0640 - mae: 0.1892 - val_loss: 0.1047 - val_mse: 0.0943 - val_mae: 0.2269\n",
      "Epoch 610/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0732 - mse: 0.0628 - mae: 0.1852 - val_loss: 0.0984 - val_mse: 0.0881 - val_mae: 0.2114\n",
      "Epoch 611/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0733 - mse: 0.0629 - mae: 0.1868 - val_loss: 0.0998 - val_mse: 0.0894 - val_mae: 0.2228\n",
      "Epoch 612/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0739 - mse: 0.0635 - mae: 0.1888 - val_loss: 0.1024 - val_mse: 0.0920 - val_mae: 0.2204\n",
      "Epoch 613/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0738 - mse: 0.0634 - mae: 0.1870 - val_loss: 0.0959 - val_mse: 0.0855 - val_mae: 0.2143\n",
      "Epoch 614/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0737 - mse: 0.0633 - mae: 0.1889 - val_loss: 0.0981 - val_mse: 0.0877 - val_mae: 0.2140\n",
      "Epoch 615/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0736 - mse: 0.0632 - mae: 0.1863 - val_loss: 0.0999 - val_mse: 0.0895 - val_mae: 0.2174\n",
      "Epoch 616/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0729 - mse: 0.0625 - mae: 0.1865 - val_loss: 0.0992 - val_mse: 0.0888 - val_mae: 0.2206\n",
      "Epoch 617/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0730 - mse: 0.0626 - mae: 0.1860 - val_loss: 0.1013 - val_mse: 0.0909 - val_mae: 0.2219\n",
      "Epoch 618/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0732 - mse: 0.0628 - mae: 0.1881 - val_loss: 0.1046 - val_mse: 0.0942 - val_mae: 0.2270\n",
      "Epoch 619/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0719 - mse: 0.0615 - mae: 0.1837 - val_loss: 0.0979 - val_mse: 0.0875 - val_mae: 0.2180\n",
      "Epoch 620/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0723 - mse: 0.0619 - mae: 0.1844 - val_loss: 0.0994 - val_mse: 0.0890 - val_mae: 0.2206\n",
      "Epoch 621/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0724 - mse: 0.0620 - mae: 0.1866 - val_loss: 0.1012 - val_mse: 0.0908 - val_mae: 0.2143\n",
      "Epoch 622/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0719 - mse: 0.0615 - mae: 0.1846 - val_loss: 0.0954 - val_mse: 0.0850 - val_mae: 0.2109\n",
      "Epoch 623/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0737 - mse: 0.0633 - mae: 0.1906 - val_loss: 0.1014 - val_mse: 0.0910 - val_mae: 0.2201\n",
      "Epoch 624/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0726 - mse: 0.0622 - mae: 0.1869 - val_loss: 0.0944 - val_mse: 0.0839 - val_mae: 0.2097\n",
      "Epoch 625/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0719 - mse: 0.0615 - mae: 0.1846 - val_loss: 0.0975 - val_mse: 0.0871 - val_mae: 0.2107\n",
      "Epoch 626/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0712 - mse: 0.0608 - mae: 0.1830 - val_loss: 0.0968 - val_mse: 0.0864 - val_mae: 0.2164\n",
      "Epoch 627/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0715 - mse: 0.0611 - mae: 0.1851 - val_loss: 0.0948 - val_mse: 0.0844 - val_mae: 0.2113\n",
      "Epoch 628/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0718 - mse: 0.0613 - mae: 0.1853 - val_loss: 0.0964 - val_mse: 0.0859 - val_mae: 0.2078\n",
      "Epoch 629/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0727 - mse: 0.0622 - mae: 0.1865 - val_loss: 0.0948 - val_mse: 0.0844 - val_mae: 0.2115\n",
      "Epoch 630/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0717 - mse: 0.0612 - mae: 0.1847 - val_loss: 0.0963 - val_mse: 0.0858 - val_mae: 0.2116\n",
      "Epoch 631/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0712 - mse: 0.0608 - mae: 0.1841 - val_loss: 0.0942 - val_mse: 0.0837 - val_mae: 0.2108\n",
      "Epoch 632/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0705 - mse: 0.0601 - mae: 0.1826 - val_loss: 0.0951 - val_mse: 0.0846 - val_mae: 0.2108\n",
      "Epoch 633/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0712 - mse: 0.0608 - mae: 0.1842 - val_loss: 0.1015 - val_mse: 0.0910 - val_mae: 0.2184\n",
      "Epoch 634/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0719 - mse: 0.0615 - mae: 0.1852 - val_loss: 0.1041 - val_mse: 0.0936 - val_mae: 0.2271\n",
      "Epoch 635/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0731 - mse: 0.0626 - mae: 0.1892 - val_loss: 0.1044 - val_mse: 0.0939 - val_mae: 0.2282\n",
      "Epoch 636/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0724 - mse: 0.0619 - mae: 0.1841 - val_loss: 0.1031 - val_mse: 0.0927 - val_mae: 0.2216\n",
      "Epoch 637/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0702 - mse: 0.0597 - mae: 0.1815 - val_loss: 0.0916 - val_mse: 0.0811 - val_mae: 0.2054\n",
      "Epoch 638/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0699 - mse: 0.0594 - mae: 0.1831 - val_loss: 0.0977 - val_mse: 0.0872 - val_mae: 0.2198\n",
      "Epoch 639/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0711 - mse: 0.0606 - mae: 0.1847 - val_loss: 0.1008 - val_mse: 0.0903 - val_mae: 0.2204\n",
      "Epoch 640/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0714 - mse: 0.0609 - mae: 0.1861 - val_loss: 0.0917 - val_mse: 0.0812 - val_mae: 0.2036\n",
      "Epoch 641/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0702 - mse: 0.0597 - mae: 0.1827 - val_loss: 0.0942 - val_mse: 0.0837 - val_mae: 0.2098\n",
      "Epoch 642/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0711 - mse: 0.0606 - mae: 0.1842 - val_loss: 0.0948 - val_mse: 0.0843 - val_mae: 0.2069\n",
      "Epoch 643/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0706 - mse: 0.0601 - mae: 0.1833 - val_loss: 0.0916 - val_mse: 0.0811 - val_mae: 0.2029\n",
      "Epoch 644/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0707 - mse: 0.0602 - mae: 0.1839 - val_loss: 0.0928 - val_mse: 0.0823 - val_mae: 0.2042\n",
      "Epoch 645/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0696 - mse: 0.0591 - mae: 0.1826 - val_loss: 0.1042 - val_mse: 0.0937 - val_mae: 0.2285\n",
      "Epoch 646/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0722 - mse: 0.0617 - mae: 0.1871 - val_loss: 0.0955 - val_mse: 0.0850 - val_mae: 0.2121\n",
      "Epoch 647/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0698 - mse: 0.0593 - mae: 0.1826 - val_loss: 0.0923 - val_mse: 0.0818 - val_mae: 0.2079\n",
      "Epoch 648/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0703 - mse: 0.0598 - mae: 0.1834 - val_loss: 0.0951 - val_mse: 0.0846 - val_mae: 0.2117\n",
      "Epoch 649/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0699 - mse: 0.0594 - mae: 0.1838 - val_loss: 0.0948 - val_mse: 0.0843 - val_mae: 0.2127\n",
      "Epoch 650/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0695 - mse: 0.0589 - mae: 0.1820 - val_loss: 0.0912 - val_mse: 0.0806 - val_mae: 0.2021\n",
      "Epoch 651/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0706 - mse: 0.0600 - mae: 0.1830 - val_loss: 0.0930 - val_mse: 0.0824 - val_mae: 0.2018\n",
      "Epoch 652/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0710 - mse: 0.0605 - mae: 0.1863 - val_loss: 0.0870 - val_mse: 0.0765 - val_mae: 0.1938\n",
      "Epoch 653/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0714 - mse: 0.0609 - mae: 0.1889 - val_loss: 0.0992 - val_mse: 0.0887 - val_mae: 0.2195\n",
      "Epoch 654/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0704 - mse: 0.0599 - mae: 0.1837 - val_loss: 0.0961 - val_mse: 0.0855 - val_mae: 0.2087\n",
      "Epoch 655/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0693 - mse: 0.0588 - mae: 0.1820 - val_loss: 0.0876 - val_mse: 0.0771 - val_mae: 0.1986\n",
      "Epoch 656/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0685 - mse: 0.0580 - mae: 0.1806 - val_loss: 0.0940 - val_mse: 0.0835 - val_mae: 0.2067\n",
      "Epoch 657/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0708 - mse: 0.0603 - mae: 0.1841 - val_loss: 0.0982 - val_mse: 0.0876 - val_mae: 0.2140\n",
      "Epoch 658/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0707 - mse: 0.0601 - mae: 0.1859 - val_loss: 0.0935 - val_mse: 0.0829 - val_mae: 0.2105\n",
      "Epoch 659/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0686 - mse: 0.0580 - mae: 0.1814 - val_loss: 0.0954 - val_mse: 0.0848 - val_mae: 0.2138\n",
      "Epoch 660/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0714 - mse: 0.0608 - mae: 0.1862 - val_loss: 0.1025 - val_mse: 0.0919 - val_mae: 0.2269\n",
      "Epoch 661/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0699 - mse: 0.0594 - mae: 0.1833 - val_loss: 0.0934 - val_mse: 0.0828 - val_mae: 0.2068\n",
      "Epoch 662/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0694 - mse: 0.0588 - mae: 0.1806 - val_loss: 0.0908 - val_mse: 0.0803 - val_mae: 0.2064\n",
      "Epoch 663/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0693 - mse: 0.0587 - mae: 0.1817 - val_loss: 0.0968 - val_mse: 0.0862 - val_mae: 0.2157\n",
      "Epoch 664/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0686 - mse: 0.0580 - mae: 0.1796 - val_loss: 0.0897 - val_mse: 0.0791 - val_mae: 0.1994\n",
      "Epoch 665/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0685 - mse: 0.0579 - mae: 0.1812 - val_loss: 0.0875 - val_mse: 0.0769 - val_mae: 0.1979\n",
      "Epoch 666/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0684 - mse: 0.0579 - mae: 0.1790 - val_loss: 0.0892 - val_mse: 0.0786 - val_mae: 0.1999\n",
      "Epoch 667/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0691 - mse: 0.0585 - mae: 0.1817 - val_loss: 0.0979 - val_mse: 0.0874 - val_mae: 0.2128\n",
      "Epoch 668/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0693 - mse: 0.0588 - mae: 0.1814 - val_loss: 0.0925 - val_mse: 0.0819 - val_mae: 0.2044\n",
      "Epoch 669/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0680 - mse: 0.0574 - mae: 0.1792 - val_loss: 0.0893 - val_mse: 0.0788 - val_mae: 0.2026\n",
      "Epoch 670/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0681 - mse: 0.0575 - mae: 0.1800 - val_loss: 0.0864 - val_mse: 0.0759 - val_mae: 0.1940\n",
      "Epoch 671/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0691 - mse: 0.0585 - mae: 0.1828 - val_loss: 0.0909 - val_mse: 0.0803 - val_mae: 0.2030\n",
      "Epoch 672/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0681 - mse: 0.0575 - mae: 0.1810 - val_loss: 0.0929 - val_mse: 0.0823 - val_mae: 0.2087\n",
      "Epoch 673/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0679 - mse: 0.0573 - mae: 0.1783 - val_loss: 0.0907 - val_mse: 0.0801 - val_mae: 0.2063\n",
      "Epoch 674/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0688 - mse: 0.0582 - mae: 0.1817 - val_loss: 0.0953 - val_mse: 0.0847 - val_mae: 0.2144\n",
      "Epoch 675/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0683 - mse: 0.0577 - mae: 0.1812 - val_loss: 0.0930 - val_mse: 0.0824 - val_mae: 0.2082\n",
      "Epoch 676/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0679 - mse: 0.0573 - mae: 0.1801 - val_loss: 0.0894 - val_mse: 0.0788 - val_mae: 0.2004\n",
      "Epoch 677/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0690 - mse: 0.0584 - mae: 0.1812 - val_loss: 0.0906 - val_mse: 0.0800 - val_mae: 0.2010\n",
      "Epoch 678/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0693 - mse: 0.0587 - mae: 0.1826 - val_loss: 0.0877 - val_mse: 0.0771 - val_mae: 0.1975\n",
      "Epoch 679/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0673 - mse: 0.0567 - mae: 0.1806 - val_loss: 0.0962 - val_mse: 0.0856 - val_mae: 0.2138\n",
      "Epoch 680/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0681 - mse: 0.0575 - mae: 0.1818 - val_loss: 0.0908 - val_mse: 0.0802 - val_mae: 0.2034\n",
      "Epoch 681/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0676 - mse: 0.0570 - mae: 0.1806 - val_loss: 0.0848 - val_mse: 0.0742 - val_mae: 0.1874\n",
      "Epoch 682/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0671 - mse: 0.0565 - mae: 0.1788 - val_loss: 0.0895 - val_mse: 0.0789 - val_mae: 0.2050\n",
      "Epoch 683/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0672 - mse: 0.0566 - mae: 0.1786 - val_loss: 0.0924 - val_mse: 0.0818 - val_mae: 0.2044\n",
      "Epoch 684/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0685 - mse: 0.0579 - mae: 0.1813 - val_loss: 0.0877 - val_mse: 0.0771 - val_mae: 0.1970\n",
      "Epoch 685/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0686 - mse: 0.0579 - mae: 0.1829 - val_loss: 0.0872 - val_mse: 0.0766 - val_mae: 0.1919\n",
      "Epoch 686/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0692 - mse: 0.0585 - mae: 0.1832 - val_loss: 0.0890 - val_mse: 0.0784 - val_mae: 0.1981\n",
      "Epoch 687/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0683 - mse: 0.0577 - mae: 0.1821 - val_loss: 0.0903 - val_mse: 0.0797 - val_mae: 0.2010\n",
      "Epoch 688/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0663 - mse: 0.0557 - mae: 0.1762 - val_loss: 0.0908 - val_mse: 0.0802 - val_mae: 0.2074\n",
      "Epoch 689/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0677 - mse: 0.0571 - mae: 0.1797 - val_loss: 0.0902 - val_mse: 0.0796 - val_mae: 0.2062\n",
      "Epoch 690/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0688 - mse: 0.0581 - mae: 0.1831 - val_loss: 0.0881 - val_mse: 0.0774 - val_mae: 0.1999\n",
      "Epoch 691/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0667 - mse: 0.0561 - mae: 0.1794 - val_loss: 0.0847 - val_mse: 0.0741 - val_mae: 0.1944\n",
      "Epoch 692/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0662 - mse: 0.0556 - mae: 0.1771 - val_loss: 0.0866 - val_mse: 0.0759 - val_mae: 0.1945\n",
      "Epoch 693/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0660 - mse: 0.0554 - mae: 0.1768 - val_loss: 0.0867 - val_mse: 0.0761 - val_mae: 0.1950\n",
      "Epoch 694/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0656 - mse: 0.0550 - mae: 0.1760 - val_loss: 0.0931 - val_mse: 0.0824 - val_mae: 0.2105\n",
      "Epoch 695/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0666 - mse: 0.0559 - mae: 0.1771 - val_loss: 0.0880 - val_mse: 0.0773 - val_mae: 0.1985\n",
      "Epoch 696/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0653 - mse: 0.0547 - mae: 0.1747 - val_loss: 0.0868 - val_mse: 0.0761 - val_mae: 0.1999\n",
      "Epoch 697/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0665 - mse: 0.0559 - mae: 0.1787 - val_loss: 0.0845 - val_mse: 0.0738 - val_mae: 0.1861\n",
      "Epoch 698/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0671 - mse: 0.0565 - mae: 0.1784 - val_loss: 0.0850 - val_mse: 0.0744 - val_mae: 0.1961\n",
      "Epoch 699/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0670 - mse: 0.0564 - mae: 0.1793 - val_loss: 0.0855 - val_mse: 0.0748 - val_mae: 0.1914\n",
      "Epoch 700/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0674 - mse: 0.0567 - mae: 0.1814 - val_loss: 0.0836 - val_mse: 0.0730 - val_mae: 0.1931\n",
      "Epoch 701/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0647 - mse: 0.0541 - mae: 0.1745 - val_loss: 0.0904 - val_mse: 0.0798 - val_mae: 0.2029\n",
      "Epoch 702/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0656 - mse: 0.0549 - mae: 0.1767 - val_loss: 0.0883 - val_mse: 0.0776 - val_mae: 0.2009\n",
      "Epoch 703/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0676 - mse: 0.0570 - mae: 0.1816 - val_loss: 0.0871 - val_mse: 0.0764 - val_mae: 0.1952\n",
      "Epoch 704/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0673 - mse: 0.0567 - mae: 0.1789 - val_loss: 0.0873 - val_mse: 0.0766 - val_mae: 0.1970\n",
      "Epoch 705/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0683 - mse: 0.0576 - mae: 0.1827 - val_loss: 0.0847 - val_mse: 0.0740 - val_mae: 0.1864\n",
      "Epoch 706/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0676 - mse: 0.0569 - mae: 0.1820 - val_loss: 0.0822 - val_mse: 0.0715 - val_mae: 0.1840\n",
      "Epoch 707/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0685 - mse: 0.0578 - mae: 0.1807 - val_loss: 0.0834 - val_mse: 0.0727 - val_mae: 0.1857\n",
      "Epoch 708/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0659 - mse: 0.0552 - mae: 0.1770 - val_loss: 0.0846 - val_mse: 0.0739 - val_mae: 0.1955\n",
      "Epoch 709/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0661 - mse: 0.0554 - mae: 0.1785 - val_loss: 0.0950 - val_mse: 0.0843 - val_mae: 0.2072\n",
      "Epoch 710/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0677 - mse: 0.0570 - mae: 0.1811 - val_loss: 0.0912 - val_mse: 0.0805 - val_mae: 0.2090\n",
      "Epoch 711/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0664 - mse: 0.0557 - mae: 0.1800 - val_loss: 0.0946 - val_mse: 0.0840 - val_mae: 0.2108\n",
      "Epoch 712/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0665 - mse: 0.0558 - mae: 0.1791 - val_loss: 0.0859 - val_mse: 0.0752 - val_mae: 0.1982\n",
      "Epoch 713/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0649 - mse: 0.0543 - mae: 0.1743 - val_loss: 0.0875 - val_mse: 0.0768 - val_mae: 0.1943\n",
      "Epoch 714/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0651 - mse: 0.0544 - mae: 0.1756 - val_loss: 0.0836 - val_mse: 0.0729 - val_mae: 0.1882\n",
      "Epoch 715/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0645 - mse: 0.0538 - mae: 0.1750 - val_loss: 0.0865 - val_mse: 0.0759 - val_mae: 0.1960\n",
      "Epoch 716/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0647 - mse: 0.0540 - mae: 0.1750 - val_loss: 0.0837 - val_mse: 0.0730 - val_mae: 0.1886\n",
      "Epoch 717/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0666 - mse: 0.0559 - mae: 0.1794 - val_loss: 0.0828 - val_mse: 0.0721 - val_mae: 0.1883\n",
      "Epoch 718/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0644 - mse: 0.0537 - mae: 0.1745 - val_loss: 0.0887 - val_mse: 0.0780 - val_mae: 0.2025\n",
      "Epoch 719/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0670 - mse: 0.0563 - mae: 0.1815 - val_loss: 0.0853 - val_mse: 0.0746 - val_mae: 0.1950\n",
      "Epoch 720/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0645 - mse: 0.0538 - mae: 0.1770 - val_loss: 0.0815 - val_mse: 0.0708 - val_mae: 0.1864\n",
      "Epoch 721/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0641 - mse: 0.0534 - mae: 0.1746 - val_loss: 0.0869 - val_mse: 0.0762 - val_mae: 0.1980\n",
      "Epoch 722/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0676 - mse: 0.0569 - mae: 0.1819 - val_loss: 0.0826 - val_mse: 0.0719 - val_mae: 0.1917\n",
      "Epoch 723/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0671 - mse: 0.0564 - mae: 0.1801 - val_loss: 0.0882 - val_mse: 0.0774 - val_mae: 0.1997\n",
      "Epoch 724/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0663 - mse: 0.0556 - mae: 0.1788 - val_loss: 0.0849 - val_mse: 0.0742 - val_mae: 0.1894\n",
      "Epoch 725/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0647 - mse: 0.0540 - mae: 0.1758 - val_loss: 0.0816 - val_mse: 0.0709 - val_mae: 0.1884\n",
      "Epoch 726/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0641 - mse: 0.0534 - mae: 0.1749 - val_loss: 0.0840 - val_mse: 0.0733 - val_mae: 0.1903\n",
      "Epoch 727/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0652 - mse: 0.0545 - mae: 0.1761 - val_loss: 0.0811 - val_mse: 0.0703 - val_mae: 0.1854\n",
      "Epoch 728/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0656 - mse: 0.0548 - mae: 0.1785 - val_loss: 0.0836 - val_mse: 0.0729 - val_mae: 0.1942\n",
      "Epoch 729/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0649 - mse: 0.0542 - mae: 0.1764 - val_loss: 0.0809 - val_mse: 0.0702 - val_mae: 0.1867\n",
      "Epoch 730/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0649 - mse: 0.0541 - mae: 0.1762 - val_loss: 0.0853 - val_mse: 0.0746 - val_mae: 0.1917\n",
      "Epoch 731/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0640 - mse: 0.0533 - mae: 0.1741 - val_loss: 0.0821 - val_mse: 0.0713 - val_mae: 0.1904\n",
      "Epoch 732/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0655 - mse: 0.0548 - mae: 0.1789 - val_loss: 0.0795 - val_mse: 0.0688 - val_mae: 0.1777\n",
      "Epoch 733/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0662 - mse: 0.0555 - mae: 0.1797 - val_loss: 0.0855 - val_mse: 0.0748 - val_mae: 0.1950\n",
      "Epoch 734/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0638 - mse: 0.0531 - mae: 0.1765 - val_loss: 0.0798 - val_mse: 0.0691 - val_mae: 0.1835\n",
      "Epoch 735/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0628 - mse: 0.0521 - mae: 0.1717 - val_loss: 0.0897 - val_mse: 0.0789 - val_mae: 0.1989\n",
      "Epoch 736/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0657 - mse: 0.0549 - mae: 0.1803 - val_loss: 0.0829 - val_mse: 0.0722 - val_mae: 0.1912\n",
      "Epoch 737/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0647 - mse: 0.0540 - mae: 0.1781 - val_loss: 0.0804 - val_mse: 0.0697 - val_mae: 0.1834\n",
      "Epoch 738/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0634 - mse: 0.0527 - mae: 0.1745 - val_loss: 0.0845 - val_mse: 0.0737 - val_mae: 0.1925\n",
      "Epoch 739/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0632 - mse: 0.0525 - mae: 0.1740 - val_loss: 0.0890 - val_mse: 0.0782 - val_mae: 0.2006\n",
      "Epoch 740/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0638 - mse: 0.0531 - mae: 0.1756 - val_loss: 0.0902 - val_mse: 0.0794 - val_mae: 0.2021\n",
      "Epoch 741/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0660 - mse: 0.0552 - mae: 0.1809 - val_loss: 0.0849 - val_mse: 0.0742 - val_mae: 0.1942\n",
      "Epoch 742/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0634 - mse: 0.0526 - mae: 0.1731 - val_loss: 0.0837 - val_mse: 0.0730 - val_mae: 0.1888\n",
      "Epoch 743/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0651 - mse: 0.0544 - mae: 0.1787 - val_loss: 0.0793 - val_mse: 0.0686 - val_mae: 0.1787\n",
      "Epoch 744/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0649 - mse: 0.0541 - mae: 0.1772 - val_loss: 0.0850 - val_mse: 0.0742 - val_mae: 0.1902\n",
      "Epoch 745/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0643 - mse: 0.0535 - mae: 0.1765 - val_loss: 0.0804 - val_mse: 0.0696 - val_mae: 0.1823\n",
      "Epoch 746/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0654 - mse: 0.0546 - mae: 0.1783 - val_loss: 0.0806 - val_mse: 0.0699 - val_mae: 0.1851\n",
      "Epoch 747/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0666 - mse: 0.0559 - mae: 0.1818 - val_loss: 0.0801 - val_mse: 0.0693 - val_mae: 0.1849\n",
      "Epoch 748/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0660 - mse: 0.0552 - mae: 0.1816 - val_loss: 0.0853 - val_mse: 0.0745 - val_mae: 0.1890\n",
      "Epoch 749/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0628 - mse: 0.0520 - mae: 0.1731 - val_loss: 0.0831 - val_mse: 0.0723 - val_mae: 0.1884\n",
      "Epoch 750/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0624 - mse: 0.0516 - mae: 0.1727 - val_loss: 0.0807 - val_mse: 0.0699 - val_mae: 0.1803\n",
      "Epoch 751/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0645 - mse: 0.0538 - mae: 0.1778 - val_loss: 0.0803 - val_mse: 0.0695 - val_mae: 0.1815\n",
      "Epoch 752/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0634 - mse: 0.0526 - mae: 0.1729 - val_loss: 0.0806 - val_mse: 0.0698 - val_mae: 0.1825\n",
      "Epoch 753/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0644 - mse: 0.0536 - mae: 0.1755 - val_loss: 0.0814 - val_mse: 0.0706 - val_mae: 0.1838\n",
      "Epoch 754/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0632 - mse: 0.0524 - mae: 0.1749 - val_loss: 0.0840 - val_mse: 0.0732 - val_mae: 0.1879\n",
      "Epoch 755/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0626 - mse: 0.0518 - mae: 0.1740 - val_loss: 0.0777 - val_mse: 0.0669 - val_mae: 0.1839\n",
      "Epoch 756/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0632 - mse: 0.0524 - mae: 0.1742 - val_loss: 0.0844 - val_mse: 0.0736 - val_mae: 0.1878\n",
      "Epoch 757/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0621 - mse: 0.0513 - mae: 0.1740 - val_loss: 0.0849 - val_mse: 0.0741 - val_mae: 0.1964\n",
      "Epoch 758/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0621 - mse: 0.0513 - mae: 0.1724 - val_loss: 0.0858 - val_mse: 0.0750 - val_mae: 0.1958\n",
      "Epoch 759/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0625 - mse: 0.0517 - mae: 0.1752 - val_loss: 0.0785 - val_mse: 0.0677 - val_mae: 0.1829\n",
      "Epoch 760/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0636 - mse: 0.0528 - mae: 0.1741 - val_loss: 0.0841 - val_mse: 0.0733 - val_mae: 0.1885\n",
      "Epoch 761/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0623 - mse: 0.0515 - mae: 0.1737 - val_loss: 0.0806 - val_mse: 0.0698 - val_mae: 0.1794\n",
      "Epoch 762/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0630 - mse: 0.0522 - mae: 0.1741 - val_loss: 0.0783 - val_mse: 0.0675 - val_mae: 0.1806\n",
      "Epoch 763/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0638 - mse: 0.0530 - mae: 0.1768 - val_loss: 0.0857 - val_mse: 0.0749 - val_mae: 0.1905\n",
      "Epoch 764/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0624 - mse: 0.0515 - mae: 0.1737 - val_loss: 0.0796 - val_mse: 0.0688 - val_mae: 0.1870\n",
      "Epoch 765/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0619 - mse: 0.0511 - mae: 0.1730 - val_loss: 0.0790 - val_mse: 0.0682 - val_mae: 0.1809\n",
      "Epoch 766/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0610 - mse: 0.0502 - mae: 0.1694 - val_loss: 0.0858 - val_mse: 0.0750 - val_mae: 0.1897\n",
      "Epoch 767/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0629 - mse: 0.0521 - mae: 0.1746 - val_loss: 0.0777 - val_mse: 0.0669 - val_mae: 0.1825\n",
      "Epoch 768/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0606 - mse: 0.0498 - mae: 0.1707 - val_loss: 0.0817 - val_mse: 0.0708 - val_mae: 0.1833\n",
      "Epoch 769/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0620 - mse: 0.0512 - mae: 0.1736 - val_loss: 0.0800 - val_mse: 0.0691 - val_mae: 0.1796\n",
      "Epoch 770/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0613 - mse: 0.0505 - mae: 0.1719 - val_loss: 0.0786 - val_mse: 0.0678 - val_mae: 0.1841\n",
      "Epoch 771/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0617 - mse: 0.0509 - mae: 0.1710 - val_loss: 0.0846 - val_mse: 0.0737 - val_mae: 0.1922\n",
      "Epoch 772/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0612 - mse: 0.0504 - mae: 0.1723 - val_loss: 0.0807 - val_mse: 0.0699 - val_mae: 0.1836\n",
      "Epoch 773/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0609 - mse: 0.0501 - mae: 0.1720 - val_loss: 0.0803 - val_mse: 0.0695 - val_mae: 0.1876\n",
      "Epoch 774/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0609 - mse: 0.0501 - mae: 0.1712 - val_loss: 0.0826 - val_mse: 0.0718 - val_mae: 0.1888\n",
      "Epoch 775/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0618 - mse: 0.0510 - mae: 0.1725 - val_loss: 0.0821 - val_mse: 0.0713 - val_mae: 0.1893\n",
      "Epoch 776/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0608 - mse: 0.0499 - mae: 0.1697 - val_loss: 0.0792 - val_mse: 0.0683 - val_mae: 0.1797\n",
      "Epoch 777/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0603 - mse: 0.0495 - mae: 0.1688 - val_loss: 0.0797 - val_mse: 0.0689 - val_mae: 0.1821\n",
      "Epoch 778/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0604 - mse: 0.0495 - mae: 0.1689 - val_loss: 0.0889 - val_mse: 0.0780 - val_mae: 0.2018\n",
      "Epoch 779/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0621 - mse: 0.0512 - mae: 0.1736 - val_loss: 0.0831 - val_mse: 0.0723 - val_mae: 0.1887\n",
      "Epoch 780/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0602 - mse: 0.0494 - mae: 0.1698 - val_loss: 0.0799 - val_mse: 0.0690 - val_mae: 0.1868\n",
      "Epoch 781/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0606 - mse: 0.0497 - mae: 0.1694 - val_loss: 0.0812 - val_mse: 0.0703 - val_mae: 0.1837\n",
      "Epoch 782/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0608 - mse: 0.0500 - mae: 0.1714 - val_loss: 0.0833 - val_mse: 0.0725 - val_mae: 0.1922\n",
      "Epoch 783/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0614 - mse: 0.0505 - mae: 0.1723 - val_loss: 0.0793 - val_mse: 0.0685 - val_mae: 0.1778\n",
      "Epoch 784/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0613 - mse: 0.0504 - mae: 0.1732 - val_loss: 0.0783 - val_mse: 0.0675 - val_mae: 0.1790\n",
      "Epoch 785/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0625 - mse: 0.0516 - mae: 0.1735 - val_loss: 0.0771 - val_mse: 0.0662 - val_mae: 0.1805\n",
      "Epoch 786/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0620 - mse: 0.0512 - mae: 0.1742 - val_loss: 0.0808 - val_mse: 0.0699 - val_mae: 0.1840\n",
      "Epoch 787/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0601 - mse: 0.0492 - mae: 0.1711 - val_loss: 0.0768 - val_mse: 0.0660 - val_mae: 0.1796\n",
      "Epoch 788/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0614 - mse: 0.0505 - mae: 0.1723 - val_loss: 0.0846 - val_mse: 0.0737 - val_mae: 0.1931\n",
      "Epoch 789/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0618 - mse: 0.0510 - mae: 0.1729 - val_loss: 0.0816 - val_mse: 0.0707 - val_mae: 0.1861\n",
      "Epoch 790/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0624 - mse: 0.0515 - mae: 0.1765 - val_loss: 0.0756 - val_mse: 0.0648 - val_mae: 0.1744\n",
      "Epoch 791/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0604 - mse: 0.0495 - mae: 0.1703 - val_loss: 0.0782 - val_mse: 0.0673 - val_mae: 0.1803\n",
      "Epoch 792/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0605 - mse: 0.0497 - mae: 0.1708 - val_loss: 0.0766 - val_mse: 0.0657 - val_mae: 0.1747\n",
      "Epoch 793/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0613 - mse: 0.0505 - mae: 0.1735 - val_loss: 0.0807 - val_mse: 0.0698 - val_mae: 0.1860\n",
      "Epoch 794/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0614 - mse: 0.0506 - mae: 0.1718 - val_loss: 0.0786 - val_mse: 0.0677 - val_mae: 0.1817\n",
      "Epoch 795/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0610 - mse: 0.0501 - mae: 0.1726 - val_loss: 0.0768 - val_mse: 0.0659 - val_mae: 0.1805\n",
      "Epoch 796/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0598 - mse: 0.0490 - mae: 0.1696 - val_loss: 0.0812 - val_mse: 0.0704 - val_mae: 0.1880\n",
      "Epoch 797/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0601 - mse: 0.0492 - mae: 0.1690 - val_loss: 0.0806 - val_mse: 0.0698 - val_mae: 0.1856\n",
      "Epoch 798/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0605 - mse: 0.0496 - mae: 0.1710 - val_loss: 0.0775 - val_mse: 0.0666 - val_mae: 0.1837\n",
      "Epoch 799/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0605 - mse: 0.0496 - mae: 0.1705 - val_loss: 0.0794 - val_mse: 0.0685 - val_mae: 0.1842\n",
      "Epoch 800/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0593 - mse: 0.0484 - mae: 0.1694 - val_loss: 0.0749 - val_mse: 0.0641 - val_mae: 0.1768\n",
      "Epoch 801/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0602 - mse: 0.0494 - mae: 0.1707 - val_loss: 0.0820 - val_mse: 0.0711 - val_mae: 0.1895\n",
      "Epoch 802/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0598 - mse: 0.0489 - mae: 0.1694 - val_loss: 0.0795 - val_mse: 0.0686 - val_mae: 0.1851\n",
      "Epoch 803/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0600 - mse: 0.0491 - mae: 0.1699 - val_loss: 0.0872 - val_mse: 0.0763 - val_mae: 0.1944\n",
      "Epoch 804/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0607 - mse: 0.0498 - mae: 0.1716 - val_loss: 0.0766 - val_mse: 0.0657 - val_mae: 0.1793\n",
      "Epoch 805/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0596 - mse: 0.0487 - mae: 0.1711 - val_loss: 0.0870 - val_mse: 0.0761 - val_mae: 0.1976\n",
      "Epoch 806/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0609 - mse: 0.0500 - mae: 0.1726 - val_loss: 0.0819 - val_mse: 0.0711 - val_mae: 0.1852\n",
      "Epoch 807/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0598 - mse: 0.0489 - mae: 0.1692 - val_loss: 0.0791 - val_mse: 0.0682 - val_mae: 0.1823\n",
      "Epoch 808/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0604 - mse: 0.0495 - mae: 0.1721 - val_loss: 0.0797 - val_mse: 0.0688 - val_mae: 0.1840\n",
      "Epoch 809/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0602 - mse: 0.0493 - mae: 0.1717 - val_loss: 0.0830 - val_mse: 0.0721 - val_mae: 0.1902\n",
      "Epoch 810/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0610 - mse: 0.0501 - mae: 0.1740 - val_loss: 0.0759 - val_mse: 0.0650 - val_mae: 0.1799\n",
      "Epoch 811/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0609 - mse: 0.0500 - mae: 0.1723 - val_loss: 0.0815 - val_mse: 0.0706 - val_mae: 0.1840\n",
      "Epoch 812/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0601 - mse: 0.0492 - mae: 0.1710 - val_loss: 0.0762 - val_mse: 0.0653 - val_mae: 0.1758\n",
      "Epoch 813/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0595 - mse: 0.0486 - mae: 0.1700 - val_loss: 0.0771 - val_mse: 0.0662 - val_mae: 0.1824\n",
      "Epoch 814/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0594 - mse: 0.0485 - mae: 0.1694 - val_loss: 0.0800 - val_mse: 0.0691 - val_mae: 0.1787\n",
      "Epoch 815/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0591 - mse: 0.0482 - mae: 0.1686 - val_loss: 0.0747 - val_mse: 0.0638 - val_mae: 0.1759\n",
      "Epoch 816/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0606 - mse: 0.0497 - mae: 0.1726 - val_loss: 0.0788 - val_mse: 0.0678 - val_mae: 0.1802\n",
      "Epoch 817/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0596 - mse: 0.0486 - mae: 0.1701 - val_loss: 0.0749 - val_mse: 0.0640 - val_mae: 0.1734\n",
      "Epoch 818/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0600 - mse: 0.0491 - mae: 0.1693 - val_loss: 0.0778 - val_mse: 0.0669 - val_mae: 0.1772\n",
      "Epoch 819/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0605 - mse: 0.0496 - mae: 0.1715 - val_loss: 0.0777 - val_mse: 0.0668 - val_mae: 0.1781\n",
      "Epoch 820/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0597 - mse: 0.0488 - mae: 0.1706 - val_loss: 0.0772 - val_mse: 0.0662 - val_mae: 0.1813\n",
      "Epoch 821/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0597 - mse: 0.0488 - mae: 0.1723 - val_loss: 0.0822 - val_mse: 0.0713 - val_mae: 0.1909\n",
      "Epoch 822/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0600 - mse: 0.0491 - mae: 0.1714 - val_loss: 0.0797 - val_mse: 0.0688 - val_mae: 0.1835\n",
      "Epoch 823/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0597 - mse: 0.0488 - mae: 0.1691 - val_loss: 0.0775 - val_mse: 0.0665 - val_mae: 0.1796\n",
      "Epoch 824/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0594 - mse: 0.0485 - mae: 0.1711 - val_loss: 0.0743 - val_mse: 0.0634 - val_mae: 0.1728\n",
      "Epoch 825/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0598 - mse: 0.0489 - mae: 0.1710 - val_loss: 0.0765 - val_mse: 0.0656 - val_mae: 0.1787\n",
      "Epoch 826/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0588 - mse: 0.0479 - mae: 0.1670 - val_loss: 0.0797 - val_mse: 0.0687 - val_mae: 0.1812\n",
      "Epoch 827/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0589 - mse: 0.0479 - mae: 0.1690 - val_loss: 0.0733 - val_mse: 0.0624 - val_mae: 0.1736\n",
      "Epoch 828/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0592 - mse: 0.0482 - mae: 0.1696 - val_loss: 0.0881 - val_mse: 0.0771 - val_mae: 0.1986\n",
      "Epoch 829/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0596 - mse: 0.0487 - mae: 0.1707 - val_loss: 0.0765 - val_mse: 0.0655 - val_mae: 0.1748\n",
      "Epoch 830/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0580 - mse: 0.0471 - mae: 0.1671 - val_loss: 0.0755 - val_mse: 0.0646 - val_mae: 0.1794\n",
      "Epoch 831/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0588 - mse: 0.0479 - mae: 0.1682 - val_loss: 0.0850 - val_mse: 0.0741 - val_mae: 0.1897\n",
      "Epoch 832/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0594 - mse: 0.0484 - mae: 0.1701 - val_loss: 0.0757 - val_mse: 0.0647 - val_mae: 0.1810\n",
      "Epoch 833/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0585 - mse: 0.0476 - mae: 0.1671 - val_loss: 0.0752 - val_mse: 0.0643 - val_mae: 0.1764\n",
      "Epoch 834/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0588 - mse: 0.0479 - mae: 0.1690 - val_loss: 0.0783 - val_mse: 0.0673 - val_mae: 0.1797\n",
      "Epoch 835/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0596 - mse: 0.0486 - mae: 0.1700 - val_loss: 0.0761 - val_mse: 0.0652 - val_mae: 0.1709\n",
      "Epoch 836/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0596 - mse: 0.0487 - mae: 0.1703 - val_loss: 0.0763 - val_mse: 0.0653 - val_mae: 0.1827\n",
      "Epoch 837/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0590 - mse: 0.0480 - mae: 0.1697 - val_loss: 0.0727 - val_mse: 0.0617 - val_mae: 0.1690\n",
      "Epoch 838/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0578 - mse: 0.0469 - mae: 0.1658 - val_loss: 0.0816 - val_mse: 0.0707 - val_mae: 0.1882\n",
      "Epoch 839/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0582 - mse: 0.0472 - mae: 0.1665 - val_loss: 0.0752 - val_mse: 0.0642 - val_mae: 0.1726\n",
      "Epoch 840/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0586 - mse: 0.0476 - mae: 0.1684 - val_loss: 0.0730 - val_mse: 0.0620 - val_mae: 0.1713\n",
      "Epoch 841/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0580 - mse: 0.0470 - mae: 0.1669 - val_loss: 0.0762 - val_mse: 0.0652 - val_mae: 0.1785\n",
      "Epoch 842/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0584 - mse: 0.0474 - mae: 0.1659 - val_loss: 0.0772 - val_mse: 0.0663 - val_mae: 0.1763\n",
      "Epoch 843/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0578 - mse: 0.0469 - mae: 0.1679 - val_loss: 0.0747 - val_mse: 0.0637 - val_mae: 0.1760\n",
      "Epoch 844/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0581 - mse: 0.0472 - mae: 0.1685 - val_loss: 0.0768 - val_mse: 0.0659 - val_mae: 0.1795\n",
      "Epoch 845/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0582 - mse: 0.0472 - mae: 0.1701 - val_loss: 0.0782 - val_mse: 0.0672 - val_mae: 0.1878\n",
      "Epoch 846/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0596 - mse: 0.0487 - mae: 0.1693 - val_loss: 0.0768 - val_mse: 0.0658 - val_mae: 0.1760\n",
      "Epoch 847/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0585 - mse: 0.0475 - mae: 0.1679 - val_loss: 0.0728 - val_mse: 0.0618 - val_mae: 0.1704\n",
      "Epoch 848/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0574 - mse: 0.0465 - mae: 0.1656 - val_loss: 0.0864 - val_mse: 0.0755 - val_mae: 0.1985\n",
      "Epoch 849/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0613 - mse: 0.0504 - mae: 0.1750 - val_loss: 0.0745 - val_mse: 0.0636 - val_mae: 0.1764\n",
      "Epoch 850/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0595 - mse: 0.0485 - mae: 0.1696 - val_loss: 0.0793 - val_mse: 0.0684 - val_mae: 0.1881\n",
      "Epoch 851/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0583 - mse: 0.0474 - mae: 0.1682 - val_loss: 0.0736 - val_mse: 0.0627 - val_mae: 0.1697\n",
      "Epoch 852/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0602 - mse: 0.0493 - mae: 0.1715 - val_loss: 0.0740 - val_mse: 0.0630 - val_mae: 0.1712\n",
      "Epoch 853/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0584 - mse: 0.0475 - mae: 0.1685 - val_loss: 0.0791 - val_mse: 0.0681 - val_mae: 0.1864\n",
      "Epoch 854/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0582 - mse: 0.0473 - mae: 0.1685 - val_loss: 0.0785 - val_mse: 0.0675 - val_mae: 0.1838\n",
      "Epoch 855/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0579 - mse: 0.0469 - mae: 0.1679 - val_loss: 0.0754 - val_mse: 0.0644 - val_mae: 0.1739\n",
      "Epoch 856/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0599 - mse: 0.0490 - mae: 0.1727 - val_loss: 0.0719 - val_mse: 0.0609 - val_mae: 0.1669\n",
      "Epoch 857/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0579 - mse: 0.0469 - mae: 0.1677 - val_loss: 0.0780 - val_mse: 0.0670 - val_mae: 0.1838\n",
      "Epoch 858/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0584 - mse: 0.0474 - mae: 0.1684 - val_loss: 0.0793 - val_mse: 0.0683 - val_mae: 0.1829\n",
      "Epoch 859/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0591 - mse: 0.0481 - mae: 0.1697 - val_loss: 0.0822 - val_mse: 0.0712 - val_mae: 0.1904\n",
      "Epoch 860/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0589 - mse: 0.0479 - mae: 0.1693 - val_loss: 0.0758 - val_mse: 0.0648 - val_mae: 0.1785\n",
      "Epoch 861/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0573 - mse: 0.0463 - mae: 0.1657 - val_loss: 0.0752 - val_mse: 0.0642 - val_mae: 0.1729\n",
      "Epoch 862/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0579 - mse: 0.0469 - mae: 0.1670 - val_loss: 0.0745 - val_mse: 0.0635 - val_mae: 0.1770\n",
      "Epoch 863/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0583 - mse: 0.0473 - mae: 0.1672 - val_loss: 0.0810 - val_mse: 0.0700 - val_mae: 0.1828\n",
      "Epoch 864/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0585 - mse: 0.0475 - mae: 0.1696 - val_loss: 0.0776 - val_mse: 0.0666 - val_mae: 0.1817\n",
      "Epoch 865/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0573 - mse: 0.0463 - mae: 0.1674 - val_loss: 0.0729 - val_mse: 0.0619 - val_mae: 0.1730\n",
      "Epoch 866/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0581 - mse: 0.0472 - mae: 0.1686 - val_loss: 0.0791 - val_mse: 0.0681 - val_mae: 0.1816\n",
      "Epoch 867/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0581 - mse: 0.0471 - mae: 0.1683 - val_loss: 0.0728 - val_mse: 0.0618 - val_mae: 0.1710\n",
      "Epoch 868/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0576 - mse: 0.0466 - mae: 0.1669 - val_loss: 0.0760 - val_mse: 0.0650 - val_mae: 0.1801\n",
      "Epoch 869/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0574 - mse: 0.0464 - mae: 0.1664 - val_loss: 0.0757 - val_mse: 0.0647 - val_mae: 0.1740\n",
      "Epoch 870/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0586 - mse: 0.0476 - mae: 0.1678 - val_loss: 0.0718 - val_mse: 0.0608 - val_mae: 0.1687\n",
      "Epoch 871/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0585 - mse: 0.0475 - mae: 0.1686 - val_loss: 0.0715 - val_mse: 0.0605 - val_mae: 0.1714\n",
      "Epoch 872/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0571 - mse: 0.0462 - mae: 0.1657 - val_loss: 0.0848 - val_mse: 0.0738 - val_mae: 0.1938\n",
      "Epoch 873/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0589 - mse: 0.0479 - mae: 0.1695 - val_loss: 0.0754 - val_mse: 0.0644 - val_mae: 0.1758\n",
      "Epoch 874/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0583 - mse: 0.0474 - mae: 0.1698 - val_loss: 0.0702 - val_mse: 0.0592 - val_mae: 0.1639\n",
      "Epoch 875/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0575 - mse: 0.0465 - mae: 0.1668 - val_loss: 0.0784 - val_mse: 0.0674 - val_mae: 0.1776\n",
      "Epoch 876/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0605 - mse: 0.0495 - mae: 0.1721 - val_loss: 0.0712 - val_mse: 0.0602 - val_mae: 0.1690\n",
      "Epoch 877/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0579 - mse: 0.0469 - mae: 0.1681 - val_loss: 0.0737 - val_mse: 0.0627 - val_mae: 0.1715\n",
      "Epoch 878/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0575 - mse: 0.0465 - mae: 0.1668 - val_loss: 0.0757 - val_mse: 0.0647 - val_mae: 0.1760\n",
      "Epoch 879/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0579 - mse: 0.0469 - mae: 0.1695 - val_loss: 0.0717 - val_mse: 0.0607 - val_mae: 0.1693\n",
      "Epoch 880/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0583 - mse: 0.0473 - mae: 0.1682 - val_loss: 0.0731 - val_mse: 0.0621 - val_mae: 0.1696\n",
      "Epoch 881/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0588 - mse: 0.0478 - mae: 0.1708 - val_loss: 0.0734 - val_mse: 0.0624 - val_mae: 0.1713\n",
      "Epoch 882/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0571 - mse: 0.0461 - mae: 0.1663 - val_loss: 0.0710 - val_mse: 0.0600 - val_mae: 0.1675\n",
      "Epoch 883/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0574 - mse: 0.0464 - mae: 0.1662 - val_loss: 0.0723 - val_mse: 0.0613 - val_mae: 0.1685\n",
      "Epoch 884/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0572 - mse: 0.0461 - mae: 0.1657 - val_loss: 0.0737 - val_mse: 0.0627 - val_mae: 0.1717\n",
      "Epoch 885/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0573 - mse: 0.0463 - mae: 0.1666 - val_loss: 0.0774 - val_mse: 0.0664 - val_mae: 0.1829\n",
      "Epoch 886/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0579 - mse: 0.0469 - mae: 0.1698 - val_loss: 0.0743 - val_mse: 0.0632 - val_mae: 0.1755\n",
      "Epoch 887/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0574 - mse: 0.0464 - mae: 0.1674 - val_loss: 0.0756 - val_mse: 0.0646 - val_mae: 0.1738\n",
      "Epoch 888/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0577 - mse: 0.0467 - mae: 0.1673 - val_loss: 0.0737 - val_mse: 0.0627 - val_mae: 0.1747\n",
      "Epoch 889/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0573 - mse: 0.0463 - mae: 0.1663 - val_loss: 0.0720 - val_mse: 0.0610 - val_mae: 0.1698\n",
      "Epoch 890/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0582 - mse: 0.0471 - mae: 0.1672 - val_loss: 0.0705 - val_mse: 0.0595 - val_mae: 0.1680\n",
      "Epoch 891/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0572 - mse: 0.0462 - mae: 0.1687 - val_loss: 0.0778 - val_mse: 0.0668 - val_mae: 0.1852\n",
      "Epoch 892/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0570 - mse: 0.0460 - mae: 0.1664 - val_loss: 0.0798 - val_mse: 0.0688 - val_mae: 0.1875\n",
      "Epoch 893/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0604 - mse: 0.0494 - mae: 0.1744 - val_loss: 0.0764 - val_mse: 0.0653 - val_mae: 0.1768\n",
      "Epoch 894/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0596 - mse: 0.0486 - mae: 0.1736 - val_loss: 0.0749 - val_mse: 0.0639 - val_mae: 0.1750\n",
      "Epoch 895/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0579 - mse: 0.0469 - mae: 0.1688 - val_loss: 0.0742 - val_mse: 0.0632 - val_mae: 0.1770\n",
      "Epoch 896/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0576 - mse: 0.0466 - mae: 0.1678 - val_loss: 0.0863 - val_mse: 0.0752 - val_mae: 0.1987\n",
      "Epoch 897/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0592 - mse: 0.0481 - mae: 0.1719 - val_loss: 0.0709 - val_mse: 0.0598 - val_mae: 0.1668\n",
      "Epoch 898/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0571 - mse: 0.0460 - mae: 0.1664 - val_loss: 0.0699 - val_mse: 0.0589 - val_mae: 0.1663\n",
      "Epoch 899/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0567 - mse: 0.0457 - mae: 0.1661 - val_loss: 0.0723 - val_mse: 0.0613 - val_mae: 0.1689\n",
      "Epoch 900/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0572 - mse: 0.0462 - mae: 0.1672 - val_loss: 0.0740 - val_mse: 0.0630 - val_mae: 0.1736\n",
      "Epoch 901/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0562 - mse: 0.0451 - mae: 0.1633 - val_loss: 0.0709 - val_mse: 0.0598 - val_mae: 0.1657\n",
      "Epoch 902/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0565 - mse: 0.0455 - mae: 0.1642 - val_loss: 0.0783 - val_mse: 0.0672 - val_mae: 0.1819\n",
      "Epoch 903/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0569 - mse: 0.0458 - mae: 0.1669 - val_loss: 0.0701 - val_mse: 0.0591 - val_mae: 0.1669\n",
      "Epoch 904/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0566 - mse: 0.0455 - mae: 0.1652 - val_loss: 0.0716 - val_mse: 0.0606 - val_mae: 0.1682\n",
      "Epoch 905/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0570 - mse: 0.0459 - mae: 0.1672 - val_loss: 0.0755 - val_mse: 0.0644 - val_mae: 0.1808\n",
      "Epoch 906/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0577 - mse: 0.0466 - mae: 0.1677 - val_loss: 0.0738 - val_mse: 0.0628 - val_mae: 0.1730\n",
      "Epoch 907/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0588 - mse: 0.0478 - mae: 0.1707 - val_loss: 0.0738 - val_mse: 0.0628 - val_mae: 0.1772\n",
      "Epoch 908/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0574 - mse: 0.0464 - mae: 0.1667 - val_loss: 0.0707 - val_mse: 0.0596 - val_mae: 0.1648\n",
      "Epoch 909/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0581 - mse: 0.0470 - mae: 0.1671 - val_loss: 0.0722 - val_mse: 0.0612 - val_mae: 0.1710\n",
      "Epoch 910/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0564 - mse: 0.0454 - mae: 0.1654 - val_loss: 0.0702 - val_mse: 0.0591 - val_mae: 0.1653\n",
      "Epoch 911/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0562 - mse: 0.0452 - mae: 0.1642 - val_loss: 0.0782 - val_mse: 0.0672 - val_mae: 0.1826\n",
      "Epoch 912/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0565 - mse: 0.0454 - mae: 0.1646 - val_loss: 0.0743 - val_mse: 0.0632 - val_mae: 0.1773\n",
      "Epoch 913/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0573 - mse: 0.0462 - mae: 0.1671 - val_loss: 0.0729 - val_mse: 0.0619 - val_mae: 0.1714\n",
      "Epoch 914/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0572 - mse: 0.0462 - mae: 0.1645 - val_loss: 0.0770 - val_mse: 0.0660 - val_mae: 0.1778\n",
      "Epoch 915/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0582 - mse: 0.0472 - mae: 0.1687 - val_loss: 0.0732 - val_mse: 0.0621 - val_mae: 0.1719\n",
      "Epoch 916/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0581 - mse: 0.0470 - mae: 0.1672 - val_loss: 0.0707 - val_mse: 0.0596 - val_mae: 0.1667\n",
      "Epoch 917/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0573 - mse: 0.0462 - mae: 0.1676 - val_loss: 0.0681 - val_mse: 0.0571 - val_mae: 0.1628\n",
      "Epoch 918/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0586 - mse: 0.0476 - mae: 0.1717 - val_loss: 0.0726 - val_mse: 0.0615 - val_mae: 0.1715\n",
      "Epoch 919/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0581 - mse: 0.0471 - mae: 0.1696 - val_loss: 0.0772 - val_mse: 0.0662 - val_mae: 0.1793\n",
      "Epoch 920/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0574 - mse: 0.0464 - mae: 0.1676 - val_loss: 0.0722 - val_mse: 0.0611 - val_mae: 0.1634\n",
      "Epoch 921/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0574 - mse: 0.0464 - mae: 0.1678 - val_loss: 0.0708 - val_mse: 0.0597 - val_mae: 0.1701\n",
      "Epoch 922/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0564 - mse: 0.0453 - mae: 0.1633 - val_loss: 0.0733 - val_mse: 0.0623 - val_mae: 0.1709\n",
      "Epoch 923/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0564 - mse: 0.0453 - mae: 0.1640 - val_loss: 0.0696 - val_mse: 0.0586 - val_mae: 0.1655\n",
      "Epoch 924/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0447 - mae: 0.1634 - val_loss: 0.0730 - val_mse: 0.0620 - val_mae: 0.1738\n",
      "Epoch 925/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0571 - mse: 0.0460 - mae: 0.1669 - val_loss: 0.0766 - val_mse: 0.0655 - val_mae: 0.1783\n",
      "Epoch 926/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0568 - mse: 0.0457 - mae: 0.1672 - val_loss: 0.0705 - val_mse: 0.0595 - val_mae: 0.1724\n",
      "Epoch 927/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0578 - mse: 0.0467 - mae: 0.1638 - val_loss: 0.0726 - val_mse: 0.0615 - val_mae: 0.1646\n",
      "Epoch 928/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0447 - mae: 0.1640 - val_loss: 0.0744 - val_mse: 0.0634 - val_mae: 0.1777\n",
      "Epoch 929/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0566 - mse: 0.0455 - mae: 0.1663 - val_loss: 0.0761 - val_mse: 0.0650 - val_mae: 0.1805\n",
      "Epoch 930/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0568 - mse: 0.0457 - mae: 0.1653 - val_loss: 0.0734 - val_mse: 0.0623 - val_mae: 0.1753\n",
      "Epoch 931/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0562 - mse: 0.0452 - mae: 0.1651 - val_loss: 0.0701 - val_mse: 0.0591 - val_mae: 0.1674\n",
      "Epoch 932/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0573 - mse: 0.0463 - mae: 0.1664 - val_loss: 0.0701 - val_mse: 0.0590 - val_mae: 0.1659\n",
      "Epoch 933/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0562 - mse: 0.0451 - mae: 0.1648 - val_loss: 0.0730 - val_mse: 0.0619 - val_mae: 0.1715\n",
      "Epoch 934/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0567 - mse: 0.0457 - mae: 0.1655 - val_loss: 0.0715 - val_mse: 0.0605 - val_mae: 0.1709\n",
      "Epoch 935/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0555 - mse: 0.0444 - mae: 0.1635 - val_loss: 0.0687 - val_mse: 0.0576 - val_mae: 0.1619\n",
      "Epoch 936/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0559 - mse: 0.0448 - mae: 0.1644 - val_loss: 0.0685 - val_mse: 0.0574 - val_mae: 0.1627\n",
      "Epoch 937/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0579 - mse: 0.0469 - mae: 0.1689 - val_loss: 0.0807 - val_mse: 0.0696 - val_mae: 0.1846\n",
      "Epoch 938/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0574 - mse: 0.0463 - mae: 0.1690 - val_loss: 0.0711 - val_mse: 0.0600 - val_mae: 0.1743\n",
      "Epoch 939/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0565 - mse: 0.0454 - mae: 0.1657 - val_loss: 0.0747 - val_mse: 0.0636 - val_mae: 0.1715\n",
      "Epoch 940/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0574 - mse: 0.0463 - mae: 0.1667 - val_loss: 0.0684 - val_mse: 0.0573 - val_mae: 0.1664\n",
      "Epoch 941/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0564 - mse: 0.0453 - mae: 0.1663 - val_loss: 0.0694 - val_mse: 0.0583 - val_mae: 0.1667\n",
      "Epoch 942/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0567 - mse: 0.0456 - mae: 0.1655 - val_loss: 0.0750 - val_mse: 0.0639 - val_mae: 0.1749\n",
      "Epoch 943/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0579 - mse: 0.0468 - mae: 0.1690 - val_loss: 0.0744 - val_mse: 0.0633 - val_mae: 0.1810\n",
      "Epoch 944/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0569 - mse: 0.0458 - mae: 0.1658 - val_loss: 0.0703 - val_mse: 0.0593 - val_mae: 0.1672\n",
      "Epoch 945/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0562 - mse: 0.0451 - mae: 0.1653 - val_loss: 0.0693 - val_mse: 0.0583 - val_mae: 0.1604\n",
      "Epoch 946/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0589 - mse: 0.0478 - mae: 0.1720 - val_loss: 0.0735 - val_mse: 0.0624 - val_mae: 0.1766\n",
      "Epoch 947/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0561 - mse: 0.0450 - mae: 0.1679 - val_loss: 0.0758 - val_mse: 0.0647 - val_mae: 0.1813\n",
      "Epoch 948/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0563 - mse: 0.0452 - mae: 0.1647 - val_loss: 0.0751 - val_mse: 0.0640 - val_mae: 0.1774\n",
      "Epoch 949/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0554 - mse: 0.0444 - mae: 0.1624 - val_loss: 0.0693 - val_mse: 0.0583 - val_mae: 0.1668\n",
      "Epoch 950/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0556 - mse: 0.0445 - mae: 0.1622 - val_loss: 0.0727 - val_mse: 0.0616 - val_mae: 0.1723\n",
      "Epoch 951/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0447 - mae: 0.1637 - val_loss: 0.0722 - val_mse: 0.0611 - val_mae: 0.1764\n",
      "Epoch 952/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0447 - mae: 0.1638 - val_loss: 0.0795 - val_mse: 0.0684 - val_mae: 0.1846\n",
      "Epoch 953/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0564 - mse: 0.0453 - mae: 0.1659 - val_loss: 0.0694 - val_mse: 0.0583 - val_mae: 0.1685\n",
      "Epoch 954/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0551 - mse: 0.0440 - mae: 0.1621 - val_loss: 0.0718 - val_mse: 0.0607 - val_mae: 0.1676\n",
      "Epoch 955/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0561 - mse: 0.0450 - mae: 0.1644 - val_loss: 0.0707 - val_mse: 0.0596 - val_mae: 0.1688\n",
      "Epoch 956/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0557 - mse: 0.0446 - mae: 0.1651 - val_loss: 0.0709 - val_mse: 0.0598 - val_mae: 0.1702\n",
      "Epoch 957/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0447 - mae: 0.1642 - val_loss: 0.0709 - val_mse: 0.0598 - val_mae: 0.1721\n",
      "Epoch 958/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0564 - mse: 0.0453 - mae: 0.1656 - val_loss: 0.0696 - val_mse: 0.0585 - val_mae: 0.1659\n",
      "Epoch 959/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0555 - mse: 0.0444 - mae: 0.1624 - val_loss: 0.0720 - val_mse: 0.0609 - val_mae: 0.1744\n",
      "Epoch 960/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0550 - mse: 0.0439 - mae: 0.1618 - val_loss: 0.0695 - val_mse: 0.0584 - val_mae: 0.1631\n",
      "Epoch 961/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0555 - mse: 0.0443 - mae: 0.1623 - val_loss: 0.0677 - val_mse: 0.0566 - val_mae: 0.1657\n",
      "Epoch 962/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0553 - mse: 0.0442 - mae: 0.1630 - val_loss: 0.0715 - val_mse: 0.0604 - val_mae: 0.1733\n",
      "Epoch 963/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0552 - mse: 0.0441 - mae: 0.1611 - val_loss: 0.0736 - val_mse: 0.0625 - val_mae: 0.1766\n",
      "Epoch 964/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0580 - mse: 0.0469 - mae: 0.1727 - val_loss: 0.0795 - val_mse: 0.0684 - val_mae: 0.1883\n",
      "Epoch 965/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0567 - mse: 0.0456 - mae: 0.1688 - val_loss: 0.0749 - val_mse: 0.0638 - val_mae: 0.1758\n",
      "Epoch 966/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0447 - mae: 0.1648 - val_loss: 0.0677 - val_mse: 0.0566 - val_mae: 0.1647\n",
      "Epoch 967/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0555 - mse: 0.0444 - mae: 0.1636 - val_loss: 0.0727 - val_mse: 0.0616 - val_mae: 0.1735\n",
      "Epoch 968/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0556 - mse: 0.0445 - mae: 0.1630 - val_loss: 0.0684 - val_mse: 0.0573 - val_mae: 0.1614\n",
      "Epoch 969/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0552 - mse: 0.0440 - mae: 0.1613 - val_loss: 0.0685 - val_mse: 0.0574 - val_mae: 0.1655\n",
      "Epoch 970/1000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0569 - mse: 0.0458 - mae: 0.1633 - val_loss: 0.0740 - val_mse: 0.0629 - val_mae: 0.1724\n",
      "Epoch 971/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0447 - mae: 0.1640 - val_loss: 0.0668 - val_mse: 0.0557 - val_mae: 0.1631\n",
      "Epoch 972/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0560 - mse: 0.0448 - mae: 0.1659 - val_loss: 0.0695 - val_mse: 0.0584 - val_mae: 0.1654\n",
      "Epoch 973/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0556 - mse: 0.0445 - mae: 0.1610 - val_loss: 0.0732 - val_mse: 0.0620 - val_mae: 0.1724\n",
      "Epoch 974/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0549 - mse: 0.0438 - mae: 0.1626 - val_loss: 0.0700 - val_mse: 0.0588 - val_mae: 0.1714\n",
      "Epoch 975/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0559 - mse: 0.0448 - mae: 0.1657 - val_loss: 0.0723 - val_mse: 0.0612 - val_mae: 0.1707\n",
      "Epoch 976/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0553 - mse: 0.0442 - mae: 0.1617 - val_loss: 0.0682 - val_mse: 0.0571 - val_mae: 0.1639\n",
      "Epoch 977/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0551 - mse: 0.0440 - mae: 0.1612 - val_loss: 0.0713 - val_mse: 0.0602 - val_mae: 0.1735\n",
      "Epoch 978/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0560 - mse: 0.0449 - mae: 0.1634 - val_loss: 0.0698 - val_mse: 0.0587 - val_mae: 0.1683\n",
      "Epoch 979/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0565 - mse: 0.0454 - mae: 0.1655 - val_loss: 0.0720 - val_mse: 0.0609 - val_mae: 0.1735\n",
      "Epoch 980/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0561 - mse: 0.0449 - mae: 0.1636 - val_loss: 0.0703 - val_mse: 0.0592 - val_mae: 0.1696\n",
      "Epoch 981/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0566 - mse: 0.0455 - mae: 0.1663 - val_loss: 0.0697 - val_mse: 0.0586 - val_mae: 0.1665\n",
      "Epoch 982/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0551 - mse: 0.0440 - mae: 0.1635 - val_loss: 0.0708 - val_mse: 0.0597 - val_mae: 0.1734\n",
      "Epoch 983/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0447 - mae: 0.1633 - val_loss: 0.0706 - val_mse: 0.0594 - val_mae: 0.1712\n",
      "Epoch 984/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0447 - mae: 0.1624 - val_loss: 0.0715 - val_mse: 0.0604 - val_mae: 0.1740\n",
      "Epoch 985/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0547 - mse: 0.0436 - mae: 0.1606 - val_loss: 0.0716 - val_mse: 0.0605 - val_mae: 0.1689\n",
      "Epoch 986/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0551 - mse: 0.0440 - mae: 0.1607 - val_loss: 0.0748 - val_mse: 0.0637 - val_mae: 0.1833\n",
      "Epoch 987/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0568 - mse: 0.0457 - mae: 0.1673 - val_loss: 0.0671 - val_mse: 0.0560 - val_mae: 0.1627\n",
      "Epoch 988/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0553 - mse: 0.0441 - mae: 0.1619 - val_loss: 0.0688 - val_mse: 0.0577 - val_mae: 0.1627\n",
      "Epoch 989/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0549 - mse: 0.0437 - mae: 0.1617 - val_loss: 0.0695 - val_mse: 0.0583 - val_mae: 0.1721\n",
      "Epoch 990/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0551 - mse: 0.0440 - mae: 0.1624 - val_loss: 0.0692 - val_mse: 0.0581 - val_mae: 0.1659\n",
      "Epoch 991/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0545 - mse: 0.0433 - mae: 0.1628 - val_loss: 0.0785 - val_mse: 0.0674 - val_mae: 0.1879\n",
      "Epoch 992/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0571 - mse: 0.0460 - mae: 0.1661 - val_loss: 0.0748 - val_mse: 0.0636 - val_mae: 0.1835\n",
      "Epoch 993/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0562 - mse: 0.0450 - mae: 0.1644 - val_loss: 0.0705 - val_mse: 0.0594 - val_mae: 0.1641\n",
      "Epoch 994/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0554 - mse: 0.0443 - mae: 0.1626 - val_loss: 0.0700 - val_mse: 0.0589 - val_mae: 0.1679\n",
      "Epoch 995/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0548 - mse: 0.0436 - mae: 0.1623 - val_loss: 0.0731 - val_mse: 0.0620 - val_mae: 0.1779\n",
      "Epoch 996/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0562 - mse: 0.0451 - mae: 0.1654 - val_loss: 0.0718 - val_mse: 0.0606 - val_mae: 0.1752\n",
      "Epoch 997/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0546 - mse: 0.0435 - mae: 0.1612 - val_loss: 0.0693 - val_mse: 0.0582 - val_mae: 0.1640\n",
      "Epoch 998/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0549 - mse: 0.0438 - mae: 0.1625 - val_loss: 0.0687 - val_mse: 0.0576 - val_mae: 0.1665\n",
      "Epoch 999/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0549 - mse: 0.0437 - mae: 0.1607 - val_loss: 0.0685 - val_mse: 0.0574 - val_mae: 0.1635\n",
      "Epoch 1000/1000\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0557 - mse: 0.0446 - mae: 0.1647 - val_loss: 0.0695 - val_mse: 0.0583 - val_mae: 0.1686\n"
     ]
    }
   ],
   "source": [
    "############################  TRAINING ############################ \n",
    "\n",
    "training_time = time.time()\n",
    "\n",
    "history = model.fit(Xtrain, ytrain, validation_data=(Xval, yval),\n",
    "                    epochs=epochs, verbose=1)\n",
    "\n",
    "# history = model.fit(Xtrain, ytrain, validation_data=(Xval, yval),\n",
    "#                     epochs=epochs, batch_size=batch_size, verbose=1)\n",
    "training_time = training_time - time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27b32de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save entire model to a HDF5 file\n",
    "model.save(filename_out + '_model.h5')\n",
    "# Save model to XML\n",
    "utils.save_model_to_xml(filename_out + '.xml', model, Xpeaks, ypeaks, scaleInput, normalizeOutput)\n",
    "# plot predictions\n",
    "y_pred = model.predict(Xnorm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119c78dd",
   "metadata": {},
   "source": [
    "## Plot surrogate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "961026e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "############################ PLOT PREDICTIONS ############################ \n",
    "n_train = Xnorm.shape[0]\n",
    "n_rt = np.sqrt(n_train).astype(int)\n",
    "X = np.zeros((n_rt, n_rt))\n",
    "Y = np.zeros((n_rt, n_rt))\n",
    "Z_true = np.zeros((n_rt, n_rt))\n",
    "Z_pred = np.zeros((n_rt, n_rt))\n",
    "for i in range(n_rt):\n",
    "    for j in range(n_rt):\n",
    "        X[i, j] = Xnorm[i * n_rt + j, 0]\n",
    "        Y[i, j] = Xnorm[i * n_rt + j, 1]\n",
    "        Z_true[i, j] = ynorm[i * n_rt + j]\n",
    "        Z_pred[i, j] = y_pred[i * n_rt + j]\n",
    "\n",
    "fig = plt.figure(figsize=plt.figaspect(0.4))\n",
    "ax = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "cmap = plt.get_cmap('coolwarm')\n",
    "ax.plot_surface(X, Y, Z_true, cmap=cmap)\n",
    "ax.set_title('training data')\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "ax.plot_surface(X, Y, Z_pred)\n",
    "ax.set_title('learned function')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4061345",
   "metadata": {},
   "source": [
    "## Optimize surrogate model with maingopy\n",
    "\n",
    "Melon computes the relaxations of the feed forward network ````maingopy.melonpy.FeedForwardNet()```` needed by the B&B solver by providing envelopes of the activation functions (currently supported: purelin, linear, tanh, tansig, relu, relu6). The procedure is the same with gaussian processes and support vector machines.\n",
    "\n",
    "We load the trained model information from the generated XML file (see utils for details). which will be the optimization problem parameters. Then, we define the problem bounds of $D$ (see problem definition) in maingopy. Lastly, we define the evaluation function for maingopy.\n",
    "\n",
    "Maingopy then takes the envelopes of the ANN and performs a global deterministic optimization (it is  B&B solver with a reduced space formulation for these envelopes, speeding up computation: https://www.avt.rwth-aachen.de/global/show_document.asp?id=aaaaaaaaabclahw). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "261d3699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To define a model, we need to spcecialize the MAiNGOmodel class\n",
    "class Model(maingopy.MAiNGOmodel):\n",
    "    def __init__(self):\n",
    "        maingopy.MAiNGOmodel.__init__(self)\n",
    "        # Initialize feedforward neural network and load data from example csv file\n",
    "        self.ffANN = maingopy.melonpy.FeedForwardNet()\n",
    "        # folder where the model xml is stored\n",
    "        self.path = \"./data/Output/\"\n",
    "        # xml filename\n",
    "        self.fileName= \"peaks\"\n",
    "        # open them (define that it is an XML instead of a CSV)\n",
    "        self.ffANN.load_model(self.path, self.fileName, maingopy.melonpy.XML)\n",
    "\n",
    "    # We need to implement the get_variables functions for specifying the optimization varibles\n",
    "    def get_variables(self):\n",
    "        # define bounds of the original variables, so that it rescales the results fo the optimization\n",
    "        # the optimization is done with the normalized version of these values\n",
    "        variables = [ maingopy.OptimizationVariable(maingopy.Bounds(-3,3), maingopy.VT_CONTINUOUS, \"x\"),\n",
    "                      maingopy.OptimizationVariable(maingopy.Bounds(-3,3), maingopy.VT_CONTINUOUS, \"y\") ]\n",
    "        return variables\n",
    "\n",
    "    # We need to implement the evaluate function that computes the values of the objective and constraints from the variables.\n",
    "    # Note that the variables in the 'vars' argument of this function do correspond to the optimization variables defined in the get_variables function.\n",
    "    # However, they are different objects for technical reasons. The only mapping we have between them is the position in the list.\n",
    "    # The results of the evaluation (i.e., objective and constraint values) need to be return in an EvaluationContainer\n",
    "    def evaluate(self, vars):\n",
    "        x = vars[0]\n",
    "        y = vars[1]\n",
    "        \n",
    "        # Inputs to the ANN are the variables x and y\n",
    "        annInputs = [x, y]\n",
    "        \n",
    "        # Evaluate the network (in reduced-space)\n",
    "        # This returns a list, because the output of the network may be multidimensional\n",
    "        annOutputs = self.ffANN.calculate_prediction_reduced_space(annInputs)\n",
    "\n",
    "        # Set the ANN output (only 1 in this case) as objective to be minimized\n",
    "        result = maingopy.EvaluationContainer()\n",
    "        result.objective = annOutputs[0]\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "787cc45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To work with the problem, we first create an instance of the model.\n",
    "myModel = Model()\n",
    "# We then create an instance of MAiNGO, the solver, and hand it the model.\n",
    "myMAiNGO = maingopy.MAiNGO(myModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acd6df07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can have MAiNGO read a settings file:\n",
    "#fileName = \"\"\n",
    "#myMAiNGO.read_settings(fileName) # If fileName is empty, MAiNGO will attempt to open MAiNGOSettings.txt\n",
    "myMAiNGO.set_log_file_name(\".logs/my_log_file.log\")\n",
    "myMAiNGO.set_option(\"writeCsv\", True)\n",
    "myMAiNGO.set_iterations_csv_file_name(\".logs/iterations.csv\")\n",
    "myMAiNGO.set_solution_and_statistics_csv_file_name(\".logs/solution_and_statistics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccb8d0a",
   "metadata": {},
   "source": [
    "You can see the input in form of a GAMS file in case you are interested in ````./logs/my_problem_file_MAiNGO.gms````."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bcf1f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "myMAiNGO.write_model_to_file_in_other_language(writingLanguage=maingopy.LANG_GAMS, fileName=\"./logs/my_problem_file_MAiNGO.gms\", solverName=\"SCIP\", writeRelaxationOnly=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3f73e6",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "295bd166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RETCODE.GLOBALLY_OPTIMAL\n"
     ]
    }
   ],
   "source": [
    "# Finally, we call the solve routine to solve the problem.\n",
    "maingoStatus = myMAiNGO.solve()\n",
    "print(maingoStatus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f213eb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global optimum of the surrogate model: f([0.01803778752488362, -1.6162844084498615]) = -5.524714314936309\n"
     ]
    }
   ],
   "source": [
    "print(\"Global optimum of the surrogate model: f([{}, {}]) = {}\".format(myMAiNGO.get_solution_point()[0], myMAiNGO.get_solution_point()[1], myMAiNGO.get_objective_value()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2df4e212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN value at true minimum = g(0.228, -1.626) = ([-4.890676507020417], True)\n"
     ]
    }
   ],
   "source": [
    "print(\"ANN value at true minimum = g(0.228, -1.626) = {}\".format(myMAiNGO.evaluate_model_at_point(np.array([0.228, -1.626]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcea2656",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
